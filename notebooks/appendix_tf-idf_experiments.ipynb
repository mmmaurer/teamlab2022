{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_representations.tf_idf import TfIdf\n",
    "from src.data_representations.vector import Vector\n",
    "from src.data_representations.structure import Structure\n",
    "from src.classifiers.knn import Knn\n",
    "from src.preprocessing.preprocessing import Preprocessor\n",
    "from src.evaluation.evaluation import Evaluator\n",
    "from src.data_representations.bow import BOW\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(evaluator):\n",
    "    \"\"\"Runs evaluation and print out accuracy and micro precision, recall and f1\n",
    "    \"\"\"\n",
    "    print(\"Accuracy:\\n\", evaluator.accuracy())\n",
    "    print(\"Micro Precision:\\n\", evaluator.micro_precision())\n",
    "    print(\"Micro Recall:\\n\", evaluator.micro_recall())\n",
    "    print(\"Micro F-Score:\\n\", evaluator.micro_fscore())\n",
    "\n",
    "def run_prediction(classifier, test_examples, test_labels, measure, alpha, beta):\n",
    "    \"\"\"Runs prediction and evaluation\n",
    "    \"\"\"\n",
    "    predictions = classifier.predict(test_examples, k=4, measure=measure, alpha=alpha, beta=beta)\n",
    "    evaluator = Evaluator(test_labels, predictions)\n",
    "    report(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf and random choice experiments\n",
    "\n",
    "This notebook contains experiments with a random choice baseline as well as tf-idf as representation for the lyrics in different configurations of different training and test sizes as well as distance metrics and structural features.\n",
    "\n",
    "For the random baseline, a random class is picked for each of the examples in the test set.\n",
    "Since it's random, we're taking the average of **10 tests**.\n",
    "\n",
    "The first part provides a tutorial on how to run the experiments and specify core hyperparameters and settings.\n",
    "\n",
    "The second part showcases experiments with their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the experiments, either add your datasets to the data folder or change these variables to the paths to your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = \"./data/songs_train.txt\"\n",
    "filepath_test = \"./data/songs_test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run experiments with custom settings, change `read_limit` in the respective `Preprocessor`s to your training and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "dataset_train = Preprocessor(filepath=filepath_train, read_limit=10000)\n",
    "dataset_test = Preprocessor(filepath=filepath_test, read_limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create numerical representations of labels for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = list(set(dataset_train.artists) | set(dataset_test.artists))\n",
    "label_to_num = {artist:i for i, artist in enumerate(set(dataset_train.artists) | set(dataset_test.artists))}\n",
    "num_to_label = {value:key for key, value in label_to_num.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the number of processes for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_processes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the tf-idf representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfIdf()\n",
    "train = tf_idf.fit_transform(dataset_train.tokenized)\n",
    "test = tf_idf.transform(dataset_test.tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and testing examples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = [Vector([ex]) for ex in train]\n",
    "training_labels = [label_to_num[label] for label in dataset_train.artists]\n",
    "test_examples = [Vector([ex]) for ex in test]\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Knn(training_examples, training_labels, number_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the distance metric by changing the `measure` argument in `classifier.predict` from the following options\n",
    "\n",
    "- Cosine similarity: `\"cosine\"`\n",
    "\n",
    "- Euclidean distance: `\"euclidean\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_examples, k=4, measure=\"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize evaluation with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and evaluate with accuracy, micro and macro $F_1$, precision and recall as follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.accuracy()\n",
    "evaluator.micro_precision()\n",
    "evaluator.micro_recall()\n",
    "evaluator.micro_f1()\n",
    "evaluator.macro_precision()\n",
    "evaluator.macro_recall()\n",
    "evaluator.macro_f1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a full experiment and evaluation with your preferred settings, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Experiments\n",
    "\n",
    "All experiments in 1) and 2) with kNN are run with $k=4$.\n",
    "Both 1) and 2) follow this structure:\n",
    "- Random choice baseline\n",
    "\n",
    "- tf-idf\n",
    "\n",
    "    - with euclidean distance\n",
    "\n",
    "    - with cosine distance\n",
    "\n",
    "- tf-idf + structural features\n",
    "\n",
    "    - with euclidean distance\n",
    "\n",
    "    - with cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 10k training/100 test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "dataset_train = Preprocessor(filepath=filepath_train, read_limit=10000)\n",
    "dataset_test = Preprocessor(filepath=filepath_test, read_limit=100)\n",
    "\n",
    "# Create numerical representations of labels for mapping\n",
    "artists = list(set(dataset_train.artists) | set(dataset_test.artists))\n",
    "label_to_num = {artist:i for i, artist in enumerate(set(dataset_train.artists) | set(dataset_test.artists))}\n",
    "num_to_label = {value:key for key, value in label_to_num.items()}\n",
    "\n",
    "# how many process are gonna be run\n",
    "number_processes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.004\n",
      "Micro Precision:\n",
      " 0.02760854341736695\n",
      "Micro Recall:\n",
      " 0.004\n",
      "Micro F-Score:\n",
      " 0.006973639891062759\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "\n",
    "accuracy = []\n",
    "micro_precision = []\n",
    "micro_recall = []\n",
    "micro_fscore = []\n",
    "\n",
    "num_experiments = 10\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    random_labels = random.choices(range(len(artists)), k=len(test_labels))\n",
    "\n",
    "    evaluator = Evaluator(test_labels, random_labels)\n",
    "    accuracy.append(evaluator.accuracy())\n",
    "    micro_precision.append(evaluator.micro_precision())\n",
    "    micro_recall.append(evaluator.micro_recall())\n",
    "    micro_fscore.append(evaluator.micro_fscore())\n",
    "\n",
    "print(\"Accuracy:\\n\", sum(accuracy) / num_experiments)\n",
    "print(\"Micro Precision:\\n\", sum(micro_precision) / num_experiments)\n",
    "print(\"Micro Recall:\\n\", sum(micro_recall) / num_experiments)\n",
    "print(\"Micro F-Score:\\n\", sum(micro_fscore) / num_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfIdf()\n",
    "train = tf_idf.fit_transform(dataset_train.tokenized)\n",
    "test = tf_idf.transform(dataset_test.tokenized)\n",
    "\n",
    "# Initiate Knn classifier\n",
    "training_examples = [Vector([ex]) for ex in train]\n",
    "training_labels = [label_to_num[label] for label in dataset_train.artists]\n",
    "\n",
    "classifier = Knn(training_examples, training_labels, number_processes)\n",
    "\n",
    "test_examples = [Vector([ex]) for ex in test]\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "del tf_idf, train, test, training_examples, training_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with cosine and euclidean distance, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.07\n",
      "Micro Precision:\n",
      " 0.23333333333333334\n",
      "Micro Recall:\n",
      " 0.07\n",
      "Micro F-Score:\n",
      " 0.1076923076923077\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.01\n",
      "Micro Precision:\n",
      " 0.09090909090909091\n",
      "Micro Recall:\n",
      " 0.01\n",
      "Micro F-Score:\n",
      " 0.018018018018018018\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print what artist was chosen and what is the real one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pred, lab in zip(predictions, test_labels):\n",
    "#    print(num_to_label[pred], \" - \", num_to_label[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-idf + structural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfIdf()\n",
    "train = tf_idf.fit_transform(dataset_train.tokenized)\n",
    "test = tf_idf.transform(dataset_test.tokenized)\n",
    "\n",
    "train_struc =  Structure(dataset_train.tokenized)\n",
    "test_struc = Structure(dataset_test.tokenized)\n",
    "\n",
    "# Initiate Knn classifier\n",
    "training_examples = [Vector([ex, [n], [d]]) for ex, n, d in zip(train, train_struc.number_lines, train_struc.doc_length)]\n",
    "training_labels = [label_to_num[label] for label in dataset_train.artists]\n",
    "\n",
    "classifier = Knn(training_examples, training_labels, number_processes)\n",
    "\n",
    "test_examples = [Vector([ex, [n], [d]]) for ex, n, d in zip(test, test_struc.number_lines, test_struc.doc_length)]\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "del tf_idf, train, test, train_struc, test_struc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with cosine and euclidean distance, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.02\n",
      "Micro Precision:\n",
      " 0.08333333333333333\n",
      "Micro Recall:\n",
      " 0.02\n",
      "Micro F-Score:\n",
      " 0.03225806451612903\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.01\n",
      "Micro Precision:\n",
      " 0.05555555555555555\n",
      "Micro Recall:\n",
      " 0.01\n",
      "Micro F-Score:\n",
      " 0.016949152542372885\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2) 20k training/100 test sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = \"./data/songs_train.txt\"\n",
    "dataset_train = Preprocessor(filepath=filepath_train, read_limit=20000)\n",
    "filepath_test = \"./data/songs_test.txt\"\n",
    "dataset_test = Preprocessor(filepath=filepath_test, read_limit=100)\n",
    "\n",
    "# Create numerical representations of labels for mapping\n",
    "artists = list(set(dataset_train.artists) | set(dataset_test.artists))\n",
    "label_to_num = {artist:i for i, artist in enumerate(artists)}\n",
    "num_to_label = {value:key for key, value in label_to_num.items()}\n",
    "\n",
    "# how many process are gonna be run\n",
    "number_processes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.001\n",
      "Micro Precision:\n",
      " 0.006666666666666666\n",
      "Micro Recall:\n",
      " 0.001\n",
      "Micro F-Score:\n",
      " 0.0017391304347826088\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "\n",
    "accuracy = []\n",
    "micro_precision = []\n",
    "micro_recall = []\n",
    "micro_fscore = []\n",
    "\n",
    "num_experiments = 10\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    random_labels = random.choices(range(len(artists)), k=len(test_labels))\n",
    "\n",
    "    evaluator = Evaluator(test_labels, random_labels)\n",
    "    accuracy.append(evaluator.accuracy())\n",
    "    micro_precision.append(evaluator.micro_precision())\n",
    "    micro_recall.append(evaluator.micro_recall())\n",
    "    micro_fscore.append(evaluator.micro_fscore())\n",
    "\n",
    "print(\"Accuracy:\\n\", sum(accuracy) / num_experiments)\n",
    "print(\"Micro Precision:\\n\", sum(micro_precision) / num_experiments)\n",
    "print(\"Micro Recall:\\n\", sum(micro_recall) / num_experiments)\n",
    "print(\"Micro F-Score:\\n\", sum(micro_fscore) / num_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfIdf()\n",
    "train = tf_idf.fit_transform(dataset_train.tokenized)\n",
    "test = tf_idf.transform(dataset_test.tokenized)\n",
    "print('done')\n",
    "\n",
    "# Initiate Knn classifier\n",
    "training_examples = [Vector([ex]) for ex in train]\n",
    "training_labels = [label_to_num[label] for label in dataset_train.artists]\n",
    "\n",
    "classifier = Knn(training_examples, training_labels, number_processes)\n",
    "\n",
    "test_examples = [Vector([ex]) for ex in test]\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "del tf_idf, train, test, training_examples, training_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with cosine and euclidean distance, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.08\n",
      "Micro Precision:\n",
      " 0.2857142857142857\n",
      "Micro Recall:\n",
      " 0.08\n",
      "Micro F-Score:\n",
      " 0.125\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.04\n",
      "Micro Precision:\n",
      " 0.3333333333333333\n",
      "Micro Recall:\n",
      " 0.04\n",
      "Micro F-Score:\n",
      " 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-idf + structural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfIdf()\n",
    "train = tf_idf.fit_transform(dataset_train.tokenized)\n",
    "test = tf_idf.transform(dataset_test.tokenized)\n",
    "\n",
    "train_struc =  Structure(dataset_train.tokenized)\n",
    "test_struc = Structure(dataset_test.tokenized)\n",
    "\n",
    "# Initiate Knn classifier\n",
    "training_examples = [Vector([ex, [n], [d]]) for ex, n, d in zip(train, train_struc.number_lines, train_struc.doc_length)]\n",
    "training_labels = [label_to_num[label] for label in dataset_train.artists]\n",
    "\n",
    "classifier = Knn(training_examples, training_labels, number_processes)\n",
    "\n",
    "test_examples = [Vector([ex, [n], [d]]) for ex, n, d in zip(test, test_struc.number_lines, test_struc.doc_length)]\n",
    "test_labels = [label_to_num[label] for label in dataset_test.artists]\n",
    "del tf_idf, train, test, train_struc, test_struc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with cosine and euclidean distance, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.01\n",
      "Micro Precision:\n",
      " 0.05555555555555555\n",
      "Micro Recall:\n",
      " 0.01\n",
      "Micro F-Score:\n",
      " 0.016949152542372885\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.01\n",
      "Micro Precision:\n",
      " 0.07142857142857142\n",
      "Micro Recall:\n",
      " 0.01\n",
      "Micro F-Score:\n",
      " 0.01754385964912281\n"
     ]
    }
   ],
   "source": [
    "run_prediction(classifier, test_examples, test_labels, \"euclidean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
