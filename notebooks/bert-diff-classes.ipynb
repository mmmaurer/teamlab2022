{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artist classification using BERT\n",
    "This notebook is meant to be used to test the performance of bert on different sizes of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_folder = '/mount/studenten-temp1/users/knupleun/.cache/huggingface'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune BERT on artist classification\n",
    "Now we're going to fine-tune the BERT model on SequenceClassification task, using the classic pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device_num = 7\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mount/studenten-temp1/users/knupleun/.cache/huggingface'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "\n",
    "def get_dataset(folder, subclass_size):\n",
    "   dataset = load_dataset('csv',\n",
    "                        data_files={\n",
    "                           'train': dataset_folder + 'songs_train.txt',\n",
    "                           'test': dataset_folder + 'songs_test.txt',\n",
    "                           'dev': dataset_folder + 'songs_dev.txt',\n",
    "                        },\n",
    "                        column_names=['artist', 'title', 'lyrics'],\n",
    "                        sep='\\t')\n",
    "\n",
    "   # the last one takes it all\n",
    "   if subclass_size != 643:\n",
    "      set_artist = list(set(dataset['train']['artist']))[:subclass_size]\n",
    "      dataset = dataset.filter(lambda x: x['artist'] in set_artist)\n",
    "\n",
    "   union_artists = set(dataset['train']['artist']) | set(dataset['test']['artist']) | set(dataset['dev']['artist'])\n",
    "   artists = ClassLabel(names=list(union_artists))\n",
    "\n",
    "   return dataset, artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification \n",
    "from datasets import set_caching_enabled\n",
    "\n",
    "import torch\n",
    "\n",
    "def run_bert_experiment(artists, dataset):\n",
    "    # but for now I'm only gonna use bert, cuz RAM\n",
    "    model_name = \"bert-base-uncased\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                            num_labels=artists.num_classes,\n",
    "                                                            problem_type=\"single_label_classification\"\n",
    "                                                            )\n",
    "\n",
    "    #################\n",
    "    # ==== BERT ====\n",
    "    #################\n",
    "    # Turn labels to numbers and tokenize input\n",
    "    def transform(batch):\n",
    "        batch['labels'] = artists.str2int(batch['artist'])\n",
    "        return tokenizer(batch[\"lyrics\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "    set_caching_enabled(False)\n",
    "    tokenized_datasets = dataset.map(transform, batched=True, load_from_cache_file=False).remove_columns(['artist', 'title', 'lyrics'])\n",
    "\n",
    "    print(tokenized_datasets)\n",
    "    set_caching_enabled(True)\n",
    "\n",
    "    import evaluate\n",
    "    import numpy as np\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "        acc_metric = evaluate.load(\"accuracy\")\n",
    "        \n",
    "        logits, labels = eval_preds\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "        metric = acc_metric.compute(predictions=predictions, references=labels)\n",
    "        metric.update(f1_metric.compute(predictions=predictions, references=labels, average=\"micro\"))\n",
    "\n",
    "        return metric\n",
    "\n",
    "    from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-\" + str(artists.num_classes),\n",
    "        evaluation_strategy=\"steps\",\n",
    "        gradient_checkpointing=True,\n",
    "        eval_steps=25,\n",
    "        save_total_limit = 2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model = 'f1',\n",
    "        per_device_train_batch_size=32,  # batch size per device during training\n",
    "        per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['dev'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "\n",
    "    results = trainer.evaluate(tokenized_datasets['test'])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "\n",
    "def write_results(filepath, values):\n",
    "    with open(filepath, 'a+', newline='') as f:\n",
    "        csv_writer = writer(f)\n",
    "        csv_writer.writerow(values)\n",
    "\n",
    "def write_bert_results(filepath, results, dataset, artists):\n",
    "    model = \"bert\"\n",
    "    class_size = artists.num_classes\n",
    "    train_size = len(dataset['train'])\n",
    "    test_size = len(dataset['test'])\n",
    "    acc = results['eval_accuracy']\n",
    "    knn = 0\n",
    "\n",
    "    values = [model, class_size, train_size, test_size, acc, knn]\n",
    "    write_results(filepath, values)\n",
    "\n",
    "\n",
    "def write_knn_results(filepath, scores, dataset, artists):\n",
    "    model = \"bert-knn\"\n",
    "    class_size = artists.num_classes\n",
    "    train_size = len(dataset['train'])\n",
    "    test_size = len(dataset['test'])\n",
    "\n",
    "    for n, score in enumerate(scores, start=1):\n",
    "        values = [model, class_size, train_size, test_size, score, n]\n",
    "        write_results(filepath, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9031da67c545ecabcd564736d8cb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b5575c20b2b67aa1.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-816281e95d383136.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f662dad844d67f43.arrow\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a0f42e88144d5690c7a7ea12a00ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fd434556f54d7a85cb31fe938c5ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439dfd7b061241b5839fa3b7a746b9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 3628\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3628\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 465\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 446\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1075' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1075/1140 32:15 < 01:57, 0.55 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.707354</td>\n",
       "      <td>0.058296</td>\n",
       "      <td>0.058296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.616534</td>\n",
       "      <td>0.047085</td>\n",
       "      <td>0.047085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.514347</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.112108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.441247</td>\n",
       "      <td>0.096413</td>\n",
       "      <td>0.096413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.317100</td>\n",
       "      <td>0.159193</td>\n",
       "      <td>0.159193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.306845</td>\n",
       "      <td>0.143498</td>\n",
       "      <td>0.143498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.132953</td>\n",
       "      <td>0.199552</td>\n",
       "      <td>0.199552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.993761</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.242152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.899408</td>\n",
       "      <td>0.257848</td>\n",
       "      <td>0.257848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.833225</td>\n",
       "      <td>0.284753</td>\n",
       "      <td>0.284753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.781277</td>\n",
       "      <td>0.275785</td>\n",
       "      <td>0.275785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.688872</td>\n",
       "      <td>0.309417</td>\n",
       "      <td>0.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.673662</td>\n",
       "      <td>0.313901</td>\n",
       "      <td>0.313901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.665128</td>\n",
       "      <td>0.318386</td>\n",
       "      <td>0.318386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.659126</td>\n",
       "      <td>0.313901</td>\n",
       "      <td>0.313901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.587996</td>\n",
       "      <td>0.331839</td>\n",
       "      <td>0.331839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.512620</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.349776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.502139</td>\n",
       "      <td>0.345291</td>\n",
       "      <td>0.345291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.459709</td>\n",
       "      <td>0.327354</td>\n",
       "      <td>0.327354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.479468</td>\n",
       "      <td>0.336323</td>\n",
       "      <td>0.336323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.492055</td>\n",
       "      <td>0.338565</td>\n",
       "      <td>0.338565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.449968</td>\n",
       "      <td>0.327354</td>\n",
       "      <td>0.327354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.419691</td>\n",
       "      <td>0.356502</td>\n",
       "      <td>0.356502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.415395</td>\n",
       "      <td>0.367713</td>\n",
       "      <td>0.367713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.449192</td>\n",
       "      <td>0.360987</td>\n",
       "      <td>0.360987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.443960</td>\n",
       "      <td>0.356502</td>\n",
       "      <td>0.356502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.430209</td>\n",
       "      <td>0.365471</td>\n",
       "      <td>0.365471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.453904</td>\n",
       "      <td>0.363229</td>\n",
       "      <td>0.363229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.409620</td>\n",
       "      <td>0.378924</td>\n",
       "      <td>0.378924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.423253</td>\n",
       "      <td>0.363229</td>\n",
       "      <td>0.363229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.444957</td>\n",
       "      <td>0.365471</td>\n",
       "      <td>0.365471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.462055</td>\n",
       "      <td>0.367713</td>\n",
       "      <td>0.367713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.433795</td>\n",
       "      <td>0.365471</td>\n",
       "      <td>0.365471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.441100</td>\n",
       "      <td>0.360987</td>\n",
       "      <td>0.360987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.476106</td>\n",
       "      <td>0.381166</td>\n",
       "      <td>0.381166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.502414</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>0.385650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.441116</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.376682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.476813</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.376682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.487945</td>\n",
       "      <td>0.392377</td>\n",
       "      <td>0.392377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>2.511850</td>\n",
       "      <td>0.378924</td>\n",
       "      <td>0.378924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>2.510889</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.376682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>2.508162</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.376682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>2.506404</td>\n",
       "      <td>0.374439</td>\n",
       "      <td>0.374439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-1000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-1000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 446\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/checkpoint-1000 (score: 0.37892376681614354).\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee362aa18a40fa934c29a7218c3ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3b8beef4082778ba.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2188a0442942bfbe.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-333206d0ef00d780.arrow\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b4aeb4f56441a295939f033f43e306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce9ad5606674a8cb705f2ef6a5c3e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7320fcdcad84e72a341a56a8a476607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/users1/knupleun/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6776\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 6776\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 837\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 828\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='575' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 575/2120 19:05 < 51:29, 0.50 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.493178</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.416796</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.381055</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.329261</td>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.022947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.261973</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>0.048309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.167984</td>\n",
       "      <td>0.085749</td>\n",
       "      <td>0.085749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.102594</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.043418</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.100242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.971138</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.109903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.859160</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.880461</td>\n",
       "      <td>0.105072</td>\n",
       "      <td>0.105072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.810221</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.689655</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.144928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.640695</td>\n",
       "      <td>0.164251</td>\n",
       "      <td>0.164251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.608459</td>\n",
       "      <td>0.154589</td>\n",
       "      <td>0.154589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.605059</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.150966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.540739</td>\n",
       "      <td>0.179952</td>\n",
       "      <td>0.179952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.526496</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.171498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.416017</td>\n",
       "      <td>0.212560</td>\n",
       "      <td>0.212560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.883500</td>\n",
       "      <td>3.372004</td>\n",
       "      <td>0.218599</td>\n",
       "      <td>0.218599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.883500</td>\n",
       "      <td>3.380574</td>\n",
       "      <td>0.199275</td>\n",
       "      <td>0.199275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.883500</td>\n",
       "      <td>3.324005</td>\n",
       "      <td>0.208937</td>\n",
       "      <td>0.208937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.883500</td>\n",
       "      <td>3.303905</td>\n",
       "      <td>0.208937</td>\n",
       "      <td>0.208937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/checkpoint-500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/checkpoint-500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 828\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/checkpoint-500 (score: 0.21859903381642512).\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 837\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ec591a1907438da10a941ec9a5f374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-5713b749ef061dcf.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-45882ee725f4738d.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0210d7632bc5406e.arrow\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\",\n",
      "    \"133\": \"LABEL_133\",\n",
      "    \"134\": \"LABEL_134\",\n",
      "    \"135\": \"LABEL_135\",\n",
      "    \"136\": \"LABEL_136\",\n",
      "    \"137\": \"LABEL_137\",\n",
      "    \"138\": \"LABEL_138\",\n",
      "    \"139\": \"LABEL_139\",\n",
      "    \"140\": \"LABEL_140\",\n",
      "    \"141\": \"LABEL_141\",\n",
      "    \"142\": \"LABEL_142\",\n",
      "    \"143\": \"LABEL_143\",\n",
      "    \"144\": \"LABEL_144\",\n",
      "    \"145\": \"LABEL_145\",\n",
      "    \"146\": \"LABEL_146\",\n",
      "    \"147\": \"LABEL_147\",\n",
      "    \"148\": \"LABEL_148\",\n",
      "    \"149\": \"LABEL_149\",\n",
      "    \"150\": \"LABEL_150\",\n",
      "    \"151\": \"LABEL_151\",\n",
      "    \"152\": \"LABEL_152\",\n",
      "    \"153\": \"LABEL_153\",\n",
      "    \"154\": \"LABEL_154\",\n",
      "    \"155\": \"LABEL_155\",\n",
      "    \"156\": \"LABEL_156\",\n",
      "    \"157\": \"LABEL_157\",\n",
      "    \"158\": \"LABEL_158\",\n",
      "    \"159\": \"LABEL_159\",\n",
      "    \"160\": \"LABEL_160\",\n",
      "    \"161\": \"LABEL_161\",\n",
      "    \"162\": \"LABEL_162\",\n",
      "    \"163\": \"LABEL_163\",\n",
      "    \"164\": \"LABEL_164\",\n",
      "    \"165\": \"LABEL_165\",\n",
      "    \"166\": \"LABEL_166\",\n",
      "    \"167\": \"LABEL_167\",\n",
      "    \"168\": \"LABEL_168\",\n",
      "    \"169\": \"LABEL_169\",\n",
      "    \"170\": \"LABEL_170\",\n",
      "    \"171\": \"LABEL_171\",\n",
      "    \"172\": \"LABEL_172\",\n",
      "    \"173\": \"LABEL_173\",\n",
      "    \"174\": \"LABEL_174\",\n",
      "    \"175\": \"LABEL_175\",\n",
      "    \"176\": \"LABEL_176\",\n",
      "    \"177\": \"LABEL_177\",\n",
      "    \"178\": \"LABEL_178\",\n",
      "    \"179\": \"LABEL_179\",\n",
      "    \"180\": \"LABEL_180\",\n",
      "    \"181\": \"LABEL_181\",\n",
      "    \"182\": \"LABEL_182\",\n",
      "    \"183\": \"LABEL_183\",\n",
      "    \"184\": \"LABEL_184\",\n",
      "    \"185\": \"LABEL_185\",\n",
      "    \"186\": \"LABEL_186\",\n",
      "    \"187\": \"LABEL_187\",\n",
      "    \"188\": \"LABEL_188\",\n",
      "    \"189\": \"LABEL_189\",\n",
      "    \"190\": \"LABEL_190\",\n",
      "    \"191\": \"LABEL_191\",\n",
      "    \"192\": \"LABEL_192\",\n",
      "    \"193\": \"LABEL_193\",\n",
      "    \"194\": \"LABEL_194\",\n",
      "    \"195\": \"LABEL_195\",\n",
      "    \"196\": \"LABEL_196\",\n",
      "    \"197\": \"LABEL_197\",\n",
      "    \"198\": \"LABEL_198\",\n",
      "    \"199\": \"LABEL_199\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_133\": 133,\n",
      "    \"LABEL_134\": 134,\n",
      "    \"LABEL_135\": 135,\n",
      "    \"LABEL_136\": 136,\n",
      "    \"LABEL_137\": 137,\n",
      "    \"LABEL_138\": 138,\n",
      "    \"LABEL_139\": 139,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_140\": 140,\n",
      "    \"LABEL_141\": 141,\n",
      "    \"LABEL_142\": 142,\n",
      "    \"LABEL_143\": 143,\n",
      "    \"LABEL_144\": 144,\n",
      "    \"LABEL_145\": 145,\n",
      "    \"LABEL_146\": 146,\n",
      "    \"LABEL_147\": 147,\n",
      "    \"LABEL_148\": 148,\n",
      "    \"LABEL_149\": 149,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_150\": 150,\n",
      "    \"LABEL_151\": 151,\n",
      "    \"LABEL_152\": 152,\n",
      "    \"LABEL_153\": 153,\n",
      "    \"LABEL_154\": 154,\n",
      "    \"LABEL_155\": 155,\n",
      "    \"LABEL_156\": 156,\n",
      "    \"LABEL_157\": 157,\n",
      "    \"LABEL_158\": 158,\n",
      "    \"LABEL_159\": 159,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_160\": 160,\n",
      "    \"LABEL_161\": 161,\n",
      "    \"LABEL_162\": 162,\n",
      "    \"LABEL_163\": 163,\n",
      "    \"LABEL_164\": 164,\n",
      "    \"LABEL_165\": 165,\n",
      "    \"LABEL_166\": 166,\n",
      "    \"LABEL_167\": 167,\n",
      "    \"LABEL_168\": 168,\n",
      "    \"LABEL_169\": 169,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_170\": 170,\n",
      "    \"LABEL_171\": 171,\n",
      "    \"LABEL_172\": 172,\n",
      "    \"LABEL_173\": 173,\n",
      "    \"LABEL_174\": 174,\n",
      "    \"LABEL_175\": 175,\n",
      "    \"LABEL_176\": 176,\n",
      "    \"LABEL_177\": 177,\n",
      "    \"LABEL_178\": 178,\n",
      "    \"LABEL_179\": 179,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_180\": 180,\n",
      "    \"LABEL_181\": 181,\n",
      "    \"LABEL_182\": 182,\n",
      "    \"LABEL_183\": 183,\n",
      "    \"LABEL_184\": 184,\n",
      "    \"LABEL_185\": 185,\n",
      "    \"LABEL_186\": 186,\n",
      "    \"LABEL_187\": 187,\n",
      "    \"LABEL_188\": 188,\n",
      "    \"LABEL_189\": 189,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_190\": 190,\n",
      "    \"LABEL_191\": 191,\n",
      "    \"LABEL_192\": 192,\n",
      "    \"LABEL_193\": 193,\n",
      "    \"LABEL_194\": 194,\n",
      "    \"LABEL_195\": 195,\n",
      "    \"LABEL_196\": 196,\n",
      "    \"LABEL_197\": 197,\n",
      "    \"LABEL_198\": 198,\n",
      "    \"LABEL_199\": 199,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbe66d6c46246738249fa66dad63f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a4584d96394d3fa2e67b5e5f3bd8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06455de744d4ba2a70c835d4faa6a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/users1/knupleun/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13676\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 13676\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1656\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1709\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='4280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/4280 1:25:11 < 1:30:37, 0.41 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.256321</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.005266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.196747</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.010532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.143627</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.010532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.125608</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.009947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.098784</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.015214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.075015</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.046738</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.030194</td>\n",
       "      <td>0.021650</td>\n",
       "      <td>0.021650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.990882</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.018724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.921071</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>0.031012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.887064</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>0.039789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.852461</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.032183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.812041</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>0.036864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.751207</td>\n",
       "      <td>0.046811</td>\n",
       "      <td>0.046811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.711772</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>0.053833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.676705</td>\n",
       "      <td>0.056758</td>\n",
       "      <td>0.056758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.673809</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.056173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.590380</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.072557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.579796</td>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.070802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.528660</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.072557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.507356</td>\n",
       "      <td>0.075483</td>\n",
       "      <td>0.075483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.524797</td>\n",
       "      <td>0.070217</td>\n",
       "      <td>0.070217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.438331</td>\n",
       "      <td>0.088356</td>\n",
       "      <td>0.088356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.450484</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.085430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.433679</td>\n",
       "      <td>0.097718</td>\n",
       "      <td>0.097718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.360242</td>\n",
       "      <td>0.097133</td>\n",
       "      <td>0.097133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.363307</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.355607</td>\n",
       "      <td>0.099473</td>\n",
       "      <td>0.099473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.311344</td>\n",
       "      <td>0.107080</td>\n",
       "      <td>0.107080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.289139</td>\n",
       "      <td>0.114102</td>\n",
       "      <td>0.114102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.270940</td>\n",
       "      <td>0.112346</td>\n",
       "      <td>0.112346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.242877</td>\n",
       "      <td>0.124049</td>\n",
       "      <td>0.124049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.192247</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>0.125219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.180486</td>\n",
       "      <td>0.118783</td>\n",
       "      <td>0.118783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.171930</td>\n",
       "      <td>0.122294</td>\n",
       "      <td>0.122294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.143796</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>0.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.162058</td>\n",
       "      <td>0.120538</td>\n",
       "      <td>0.120538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.109306</td>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.137507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>4.908200</td>\n",
       "      <td>4.089277</td>\n",
       "      <td>0.139263</td>\n",
       "      <td>0.139263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.080696</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>0.133411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.054483</td>\n",
       "      <td>0.145114</td>\n",
       "      <td>0.145114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.048643</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>0.141018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.029884</td>\n",
       "      <td>0.145699</td>\n",
       "      <td>0.145699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.042747</td>\n",
       "      <td>0.131656</td>\n",
       "      <td>0.131656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.020076</td>\n",
       "      <td>0.138092</td>\n",
       "      <td>0.138092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.974351</td>\n",
       "      <td>0.150965</td>\n",
       "      <td>0.150965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.972492</td>\n",
       "      <td>0.142774</td>\n",
       "      <td>0.142774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>4.007986</td>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.137507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.958942</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>0.148040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.955029</td>\n",
       "      <td>0.157402</td>\n",
       "      <td>0.157402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.909051</td>\n",
       "      <td>0.160328</td>\n",
       "      <td>0.160328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.903413</td>\n",
       "      <td>0.160328</td>\n",
       "      <td>0.160328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.908618</td>\n",
       "      <td>0.161498</td>\n",
       "      <td>0.161498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.927130</td>\n",
       "      <td>0.157402</td>\n",
       "      <td>0.157402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.888874</td>\n",
       "      <td>0.167934</td>\n",
       "      <td>0.167934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.867584</td>\n",
       "      <td>0.180222</td>\n",
       "      <td>0.180222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.855568</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.170275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.865428</td>\n",
       "      <td>0.166764</td>\n",
       "      <td>0.166764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>3.883221</td>\n",
       "      <td>0.175541</td>\n",
       "      <td>0.175541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.883260</td>\n",
       "      <td>0.163839</td>\n",
       "      <td>0.163839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.845152</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.173201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.853922</td>\n",
       "      <td>0.177882</td>\n",
       "      <td>0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.815413</td>\n",
       "      <td>0.181393</td>\n",
       "      <td>0.181393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.837650</td>\n",
       "      <td>0.181978</td>\n",
       "      <td>0.181978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.819597</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.187244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.791320</td>\n",
       "      <td>0.189585</td>\n",
       "      <td>0.189585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.787977</td>\n",
       "      <td>0.190170</td>\n",
       "      <td>0.190170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.759666</td>\n",
       "      <td>0.198362</td>\n",
       "      <td>0.198362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.797283</td>\n",
       "      <td>0.189585</td>\n",
       "      <td>0.189585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.770200</td>\n",
       "      <td>0.193095</td>\n",
       "      <td>0.193095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.821539</td>\n",
       "      <td>0.174956</td>\n",
       "      <td>0.174956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.771112</td>\n",
       "      <td>0.191925</td>\n",
       "      <td>0.191925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.758600</td>\n",
       "      <td>0.203628</td>\n",
       "      <td>0.203628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.757709</td>\n",
       "      <td>0.194266</td>\n",
       "      <td>0.194266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.751688</td>\n",
       "      <td>0.196021</td>\n",
       "      <td>0.196021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.763163</td>\n",
       "      <td>0.200117</td>\n",
       "      <td>0.200117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.760222</td>\n",
       "      <td>0.196606</td>\n",
       "      <td>0.196606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.774629</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.197776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>3.486500</td>\n",
       "      <td>3.755420</td>\n",
       "      <td>0.193681</td>\n",
       "      <td>0.193681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.818900</td>\n",
       "      <td>3.730159</td>\n",
       "      <td>0.208309</td>\n",
       "      <td>0.208309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.818900</td>\n",
       "      <td>3.765797</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.197776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.818900</td>\n",
       "      <td>3.769251</td>\n",
       "      <td>0.194851</td>\n",
       "      <td>0.194851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.818900</td>\n",
       "      <td>3.791230</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.187244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-2000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-2000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1709\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/checkpoint-2000 (score: 0.2083089526038619).\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1656\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104/104 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430302d38cf64a5ea829888996d25d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a6f4339c5db7a94b.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e8c86a4a0a48f1b2.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-29f85f12698be446.arrow\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\",\n",
      "    \"133\": \"LABEL_133\",\n",
      "    \"134\": \"LABEL_134\",\n",
      "    \"135\": \"LABEL_135\",\n",
      "    \"136\": \"LABEL_136\",\n",
      "    \"137\": \"LABEL_137\",\n",
      "    \"138\": \"LABEL_138\",\n",
      "    \"139\": \"LABEL_139\",\n",
      "    \"140\": \"LABEL_140\",\n",
      "    \"141\": \"LABEL_141\",\n",
      "    \"142\": \"LABEL_142\",\n",
      "    \"143\": \"LABEL_143\",\n",
      "    \"144\": \"LABEL_144\",\n",
      "    \"145\": \"LABEL_145\",\n",
      "    \"146\": \"LABEL_146\",\n",
      "    \"147\": \"LABEL_147\",\n",
      "    \"148\": \"LABEL_148\",\n",
      "    \"149\": \"LABEL_149\",\n",
      "    \"150\": \"LABEL_150\",\n",
      "    \"151\": \"LABEL_151\",\n",
      "    \"152\": \"LABEL_152\",\n",
      "    \"153\": \"LABEL_153\",\n",
      "    \"154\": \"LABEL_154\",\n",
      "    \"155\": \"LABEL_155\",\n",
      "    \"156\": \"LABEL_156\",\n",
      "    \"157\": \"LABEL_157\",\n",
      "    \"158\": \"LABEL_158\",\n",
      "    \"159\": \"LABEL_159\",\n",
      "    \"160\": \"LABEL_160\",\n",
      "    \"161\": \"LABEL_161\",\n",
      "    \"162\": \"LABEL_162\",\n",
      "    \"163\": \"LABEL_163\",\n",
      "    \"164\": \"LABEL_164\",\n",
      "    \"165\": \"LABEL_165\",\n",
      "    \"166\": \"LABEL_166\",\n",
      "    \"167\": \"LABEL_167\",\n",
      "    \"168\": \"LABEL_168\",\n",
      "    \"169\": \"LABEL_169\",\n",
      "    \"170\": \"LABEL_170\",\n",
      "    \"171\": \"LABEL_171\",\n",
      "    \"172\": \"LABEL_172\",\n",
      "    \"173\": \"LABEL_173\",\n",
      "    \"174\": \"LABEL_174\",\n",
      "    \"175\": \"LABEL_175\",\n",
      "    \"176\": \"LABEL_176\",\n",
      "    \"177\": \"LABEL_177\",\n",
      "    \"178\": \"LABEL_178\",\n",
      "    \"179\": \"LABEL_179\",\n",
      "    \"180\": \"LABEL_180\",\n",
      "    \"181\": \"LABEL_181\",\n",
      "    \"182\": \"LABEL_182\",\n",
      "    \"183\": \"LABEL_183\",\n",
      "    \"184\": \"LABEL_184\",\n",
      "    \"185\": \"LABEL_185\",\n",
      "    \"186\": \"LABEL_186\",\n",
      "    \"187\": \"LABEL_187\",\n",
      "    \"188\": \"LABEL_188\",\n",
      "    \"189\": \"LABEL_189\",\n",
      "    \"190\": \"LABEL_190\",\n",
      "    \"191\": \"LABEL_191\",\n",
      "    \"192\": \"LABEL_192\",\n",
      "    \"193\": \"LABEL_193\",\n",
      "    \"194\": \"LABEL_194\",\n",
      "    \"195\": \"LABEL_195\",\n",
      "    \"196\": \"LABEL_196\",\n",
      "    \"197\": \"LABEL_197\",\n",
      "    \"198\": \"LABEL_198\",\n",
      "    \"199\": \"LABEL_199\",\n",
      "    \"200\": \"LABEL_200\",\n",
      "    \"201\": \"LABEL_201\",\n",
      "    \"202\": \"LABEL_202\",\n",
      "    \"203\": \"LABEL_203\",\n",
      "    \"204\": \"LABEL_204\",\n",
      "    \"205\": \"LABEL_205\",\n",
      "    \"206\": \"LABEL_206\",\n",
      "    \"207\": \"LABEL_207\",\n",
      "    \"208\": \"LABEL_208\",\n",
      "    \"209\": \"LABEL_209\",\n",
      "    \"210\": \"LABEL_210\",\n",
      "    \"211\": \"LABEL_211\",\n",
      "    \"212\": \"LABEL_212\",\n",
      "    \"213\": \"LABEL_213\",\n",
      "    \"214\": \"LABEL_214\",\n",
      "    \"215\": \"LABEL_215\",\n",
      "    \"216\": \"LABEL_216\",\n",
      "    \"217\": \"LABEL_217\",\n",
      "    \"218\": \"LABEL_218\",\n",
      "    \"219\": \"LABEL_219\",\n",
      "    \"220\": \"LABEL_220\",\n",
      "    \"221\": \"LABEL_221\",\n",
      "    \"222\": \"LABEL_222\",\n",
      "    \"223\": \"LABEL_223\",\n",
      "    \"224\": \"LABEL_224\",\n",
      "    \"225\": \"LABEL_225\",\n",
      "    \"226\": \"LABEL_226\",\n",
      "    \"227\": \"LABEL_227\",\n",
      "    \"228\": \"LABEL_228\",\n",
      "    \"229\": \"LABEL_229\",\n",
      "    \"230\": \"LABEL_230\",\n",
      "    \"231\": \"LABEL_231\",\n",
      "    \"232\": \"LABEL_232\",\n",
      "    \"233\": \"LABEL_233\",\n",
      "    \"234\": \"LABEL_234\",\n",
      "    \"235\": \"LABEL_235\",\n",
      "    \"236\": \"LABEL_236\",\n",
      "    \"237\": \"LABEL_237\",\n",
      "    \"238\": \"LABEL_238\",\n",
      "    \"239\": \"LABEL_239\",\n",
      "    \"240\": \"LABEL_240\",\n",
      "    \"241\": \"LABEL_241\",\n",
      "    \"242\": \"LABEL_242\",\n",
      "    \"243\": \"LABEL_243\",\n",
      "    \"244\": \"LABEL_244\",\n",
      "    \"245\": \"LABEL_245\",\n",
      "    \"246\": \"LABEL_246\",\n",
      "    \"247\": \"LABEL_247\",\n",
      "    \"248\": \"LABEL_248\",\n",
      "    \"249\": \"LABEL_249\",\n",
      "    \"250\": \"LABEL_250\",\n",
      "    \"251\": \"LABEL_251\",\n",
      "    \"252\": \"LABEL_252\",\n",
      "    \"253\": \"LABEL_253\",\n",
      "    \"254\": \"LABEL_254\",\n",
      "    \"255\": \"LABEL_255\",\n",
      "    \"256\": \"LABEL_256\",\n",
      "    \"257\": \"LABEL_257\",\n",
      "    \"258\": \"LABEL_258\",\n",
      "    \"259\": \"LABEL_259\",\n",
      "    \"260\": \"LABEL_260\",\n",
      "    \"261\": \"LABEL_261\",\n",
      "    \"262\": \"LABEL_262\",\n",
      "    \"263\": \"LABEL_263\",\n",
      "    \"264\": \"LABEL_264\",\n",
      "    \"265\": \"LABEL_265\",\n",
      "    \"266\": \"LABEL_266\",\n",
      "    \"267\": \"LABEL_267\",\n",
      "    \"268\": \"LABEL_268\",\n",
      "    \"269\": \"LABEL_269\",\n",
      "    \"270\": \"LABEL_270\",\n",
      "    \"271\": \"LABEL_271\",\n",
      "    \"272\": \"LABEL_272\",\n",
      "    \"273\": \"LABEL_273\",\n",
      "    \"274\": \"LABEL_274\",\n",
      "    \"275\": \"LABEL_275\",\n",
      "    \"276\": \"LABEL_276\",\n",
      "    \"277\": \"LABEL_277\",\n",
      "    \"278\": \"LABEL_278\",\n",
      "    \"279\": \"LABEL_279\",\n",
      "    \"280\": \"LABEL_280\",\n",
      "    \"281\": \"LABEL_281\",\n",
      "    \"282\": \"LABEL_282\",\n",
      "    \"283\": \"LABEL_283\",\n",
      "    \"284\": \"LABEL_284\",\n",
      "    \"285\": \"LABEL_285\",\n",
      "    \"286\": \"LABEL_286\",\n",
      "    \"287\": \"LABEL_287\",\n",
      "    \"288\": \"LABEL_288\",\n",
      "    \"289\": \"LABEL_289\",\n",
      "    \"290\": \"LABEL_290\",\n",
      "    \"291\": \"LABEL_291\",\n",
      "    \"292\": \"LABEL_292\",\n",
      "    \"293\": \"LABEL_293\",\n",
      "    \"294\": \"LABEL_294\",\n",
      "    \"295\": \"LABEL_295\",\n",
      "    \"296\": \"LABEL_296\",\n",
      "    \"297\": \"LABEL_297\",\n",
      "    \"298\": \"LABEL_298\",\n",
      "    \"299\": \"LABEL_299\",\n",
      "    \"300\": \"LABEL_300\",\n",
      "    \"301\": \"LABEL_301\",\n",
      "    \"302\": \"LABEL_302\",\n",
      "    \"303\": \"LABEL_303\",\n",
      "    \"304\": \"LABEL_304\",\n",
      "    \"305\": \"LABEL_305\",\n",
      "    \"306\": \"LABEL_306\",\n",
      "    \"307\": \"LABEL_307\",\n",
      "    \"308\": \"LABEL_308\",\n",
      "    \"309\": \"LABEL_309\",\n",
      "    \"310\": \"LABEL_310\",\n",
      "    \"311\": \"LABEL_311\",\n",
      "    \"312\": \"LABEL_312\",\n",
      "    \"313\": \"LABEL_313\",\n",
      "    \"314\": \"LABEL_314\",\n",
      "    \"315\": \"LABEL_315\",\n",
      "    \"316\": \"LABEL_316\",\n",
      "    \"317\": \"LABEL_317\",\n",
      "    \"318\": \"LABEL_318\",\n",
      "    \"319\": \"LABEL_319\",\n",
      "    \"320\": \"LABEL_320\",\n",
      "    \"321\": \"LABEL_321\",\n",
      "    \"322\": \"LABEL_322\",\n",
      "    \"323\": \"LABEL_323\",\n",
      "    \"324\": \"LABEL_324\",\n",
      "    \"325\": \"LABEL_325\",\n",
      "    \"326\": \"LABEL_326\",\n",
      "    \"327\": \"LABEL_327\",\n",
      "    \"328\": \"LABEL_328\",\n",
      "    \"329\": \"LABEL_329\",\n",
      "    \"330\": \"LABEL_330\",\n",
      "    \"331\": \"LABEL_331\",\n",
      "    \"332\": \"LABEL_332\",\n",
      "    \"333\": \"LABEL_333\",\n",
      "    \"334\": \"LABEL_334\",\n",
      "    \"335\": \"LABEL_335\",\n",
      "    \"336\": \"LABEL_336\",\n",
      "    \"337\": \"LABEL_337\",\n",
      "    \"338\": \"LABEL_338\",\n",
      "    \"339\": \"LABEL_339\",\n",
      "    \"340\": \"LABEL_340\",\n",
      "    \"341\": \"LABEL_341\",\n",
      "    \"342\": \"LABEL_342\",\n",
      "    \"343\": \"LABEL_343\",\n",
      "    \"344\": \"LABEL_344\",\n",
      "    \"345\": \"LABEL_345\",\n",
      "    \"346\": \"LABEL_346\",\n",
      "    \"347\": \"LABEL_347\",\n",
      "    \"348\": \"LABEL_348\",\n",
      "    \"349\": \"LABEL_349\",\n",
      "    \"350\": \"LABEL_350\",\n",
      "    \"351\": \"LABEL_351\",\n",
      "    \"352\": \"LABEL_352\",\n",
      "    \"353\": \"LABEL_353\",\n",
      "    \"354\": \"LABEL_354\",\n",
      "    \"355\": \"LABEL_355\",\n",
      "    \"356\": \"LABEL_356\",\n",
      "    \"357\": \"LABEL_357\",\n",
      "    \"358\": \"LABEL_358\",\n",
      "    \"359\": \"LABEL_359\",\n",
      "    \"360\": \"LABEL_360\",\n",
      "    \"361\": \"LABEL_361\",\n",
      "    \"362\": \"LABEL_362\",\n",
      "    \"363\": \"LABEL_363\",\n",
      "    \"364\": \"LABEL_364\",\n",
      "    \"365\": \"LABEL_365\",\n",
      "    \"366\": \"LABEL_366\",\n",
      "    \"367\": \"LABEL_367\",\n",
      "    \"368\": \"LABEL_368\",\n",
      "    \"369\": \"LABEL_369\",\n",
      "    \"370\": \"LABEL_370\",\n",
      "    \"371\": \"LABEL_371\",\n",
      "    \"372\": \"LABEL_372\",\n",
      "    \"373\": \"LABEL_373\",\n",
      "    \"374\": \"LABEL_374\",\n",
      "    \"375\": \"LABEL_375\",\n",
      "    \"376\": \"LABEL_376\",\n",
      "    \"377\": \"LABEL_377\",\n",
      "    \"378\": \"LABEL_378\",\n",
      "    \"379\": \"LABEL_379\",\n",
      "    \"380\": \"LABEL_380\",\n",
      "    \"381\": \"LABEL_381\",\n",
      "    \"382\": \"LABEL_382\",\n",
      "    \"383\": \"LABEL_383\",\n",
      "    \"384\": \"LABEL_384\",\n",
      "    \"385\": \"LABEL_385\",\n",
      "    \"386\": \"LABEL_386\",\n",
      "    \"387\": \"LABEL_387\",\n",
      "    \"388\": \"LABEL_388\",\n",
      "    \"389\": \"LABEL_389\",\n",
      "    \"390\": \"LABEL_390\",\n",
      "    \"391\": \"LABEL_391\",\n",
      "    \"392\": \"LABEL_392\",\n",
      "    \"393\": \"LABEL_393\",\n",
      "    \"394\": \"LABEL_394\",\n",
      "    \"395\": \"LABEL_395\",\n",
      "    \"396\": \"LABEL_396\",\n",
      "    \"397\": \"LABEL_397\",\n",
      "    \"398\": \"LABEL_398\",\n",
      "    \"399\": \"LABEL_399\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_133\": 133,\n",
      "    \"LABEL_134\": 134,\n",
      "    \"LABEL_135\": 135,\n",
      "    \"LABEL_136\": 136,\n",
      "    \"LABEL_137\": 137,\n",
      "    \"LABEL_138\": 138,\n",
      "    \"LABEL_139\": 139,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_140\": 140,\n",
      "    \"LABEL_141\": 141,\n",
      "    \"LABEL_142\": 142,\n",
      "    \"LABEL_143\": 143,\n",
      "    \"LABEL_144\": 144,\n",
      "    \"LABEL_145\": 145,\n",
      "    \"LABEL_146\": 146,\n",
      "    \"LABEL_147\": 147,\n",
      "    \"LABEL_148\": 148,\n",
      "    \"LABEL_149\": 149,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_150\": 150,\n",
      "    \"LABEL_151\": 151,\n",
      "    \"LABEL_152\": 152,\n",
      "    \"LABEL_153\": 153,\n",
      "    \"LABEL_154\": 154,\n",
      "    \"LABEL_155\": 155,\n",
      "    \"LABEL_156\": 156,\n",
      "    \"LABEL_157\": 157,\n",
      "    \"LABEL_158\": 158,\n",
      "    \"LABEL_159\": 159,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_160\": 160,\n",
      "    \"LABEL_161\": 161,\n",
      "    \"LABEL_162\": 162,\n",
      "    \"LABEL_163\": 163,\n",
      "    \"LABEL_164\": 164,\n",
      "    \"LABEL_165\": 165,\n",
      "    \"LABEL_166\": 166,\n",
      "    \"LABEL_167\": 167,\n",
      "    \"LABEL_168\": 168,\n",
      "    \"LABEL_169\": 169,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_170\": 170,\n",
      "    \"LABEL_171\": 171,\n",
      "    \"LABEL_172\": 172,\n",
      "    \"LABEL_173\": 173,\n",
      "    \"LABEL_174\": 174,\n",
      "    \"LABEL_175\": 175,\n",
      "    \"LABEL_176\": 176,\n",
      "    \"LABEL_177\": 177,\n",
      "    \"LABEL_178\": 178,\n",
      "    \"LABEL_179\": 179,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_180\": 180,\n",
      "    \"LABEL_181\": 181,\n",
      "    \"LABEL_182\": 182,\n",
      "    \"LABEL_183\": 183,\n",
      "    \"LABEL_184\": 184,\n",
      "    \"LABEL_185\": 185,\n",
      "    \"LABEL_186\": 186,\n",
      "    \"LABEL_187\": 187,\n",
      "    \"LABEL_188\": 188,\n",
      "    \"LABEL_189\": 189,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_190\": 190,\n",
      "    \"LABEL_191\": 191,\n",
      "    \"LABEL_192\": 192,\n",
      "    \"LABEL_193\": 193,\n",
      "    \"LABEL_194\": 194,\n",
      "    \"LABEL_195\": 195,\n",
      "    \"LABEL_196\": 196,\n",
      "    \"LABEL_197\": 197,\n",
      "    \"LABEL_198\": 198,\n",
      "    \"LABEL_199\": 199,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_200\": 200,\n",
      "    \"LABEL_201\": 201,\n",
      "    \"LABEL_202\": 202,\n",
      "    \"LABEL_203\": 203,\n",
      "    \"LABEL_204\": 204,\n",
      "    \"LABEL_205\": 205,\n",
      "    \"LABEL_206\": 206,\n",
      "    \"LABEL_207\": 207,\n",
      "    \"LABEL_208\": 208,\n",
      "    \"LABEL_209\": 209,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_210\": 210,\n",
      "    \"LABEL_211\": 211,\n",
      "    \"LABEL_212\": 212,\n",
      "    \"LABEL_213\": 213,\n",
      "    \"LABEL_214\": 214,\n",
      "    \"LABEL_215\": 215,\n",
      "    \"LABEL_216\": 216,\n",
      "    \"LABEL_217\": 217,\n",
      "    \"LABEL_218\": 218,\n",
      "    \"LABEL_219\": 219,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_220\": 220,\n",
      "    \"LABEL_221\": 221,\n",
      "    \"LABEL_222\": 222,\n",
      "    \"LABEL_223\": 223,\n",
      "    \"LABEL_224\": 224,\n",
      "    \"LABEL_225\": 225,\n",
      "    \"LABEL_226\": 226,\n",
      "    \"LABEL_227\": 227,\n",
      "    \"LABEL_228\": 228,\n",
      "    \"LABEL_229\": 229,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_230\": 230,\n",
      "    \"LABEL_231\": 231,\n",
      "    \"LABEL_232\": 232,\n",
      "    \"LABEL_233\": 233,\n",
      "    \"LABEL_234\": 234,\n",
      "    \"LABEL_235\": 235,\n",
      "    \"LABEL_236\": 236,\n",
      "    \"LABEL_237\": 237,\n",
      "    \"LABEL_238\": 238,\n",
      "    \"LABEL_239\": 239,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_240\": 240,\n",
      "    \"LABEL_241\": 241,\n",
      "    \"LABEL_242\": 242,\n",
      "    \"LABEL_243\": 243,\n",
      "    \"LABEL_244\": 244,\n",
      "    \"LABEL_245\": 245,\n",
      "    \"LABEL_246\": 246,\n",
      "    \"LABEL_247\": 247,\n",
      "    \"LABEL_248\": 248,\n",
      "    \"LABEL_249\": 249,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_250\": 250,\n",
      "    \"LABEL_251\": 251,\n",
      "    \"LABEL_252\": 252,\n",
      "    \"LABEL_253\": 253,\n",
      "    \"LABEL_254\": 254,\n",
      "    \"LABEL_255\": 255,\n",
      "    \"LABEL_256\": 256,\n",
      "    \"LABEL_257\": 257,\n",
      "    \"LABEL_258\": 258,\n",
      "    \"LABEL_259\": 259,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_260\": 260,\n",
      "    \"LABEL_261\": 261,\n",
      "    \"LABEL_262\": 262,\n",
      "    \"LABEL_263\": 263,\n",
      "    \"LABEL_264\": 264,\n",
      "    \"LABEL_265\": 265,\n",
      "    \"LABEL_266\": 266,\n",
      "    \"LABEL_267\": 267,\n",
      "    \"LABEL_268\": 268,\n",
      "    \"LABEL_269\": 269,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_270\": 270,\n",
      "    \"LABEL_271\": 271,\n",
      "    \"LABEL_272\": 272,\n",
      "    \"LABEL_273\": 273,\n",
      "    \"LABEL_274\": 274,\n",
      "    \"LABEL_275\": 275,\n",
      "    \"LABEL_276\": 276,\n",
      "    \"LABEL_277\": 277,\n",
      "    \"LABEL_278\": 278,\n",
      "    \"LABEL_279\": 279,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_280\": 280,\n",
      "    \"LABEL_281\": 281,\n",
      "    \"LABEL_282\": 282,\n",
      "    \"LABEL_283\": 283,\n",
      "    \"LABEL_284\": 284,\n",
      "    \"LABEL_285\": 285,\n",
      "    \"LABEL_286\": 286,\n",
      "    \"LABEL_287\": 287,\n",
      "    \"LABEL_288\": 288,\n",
      "    \"LABEL_289\": 289,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_290\": 290,\n",
      "    \"LABEL_291\": 291,\n",
      "    \"LABEL_292\": 292,\n",
      "    \"LABEL_293\": 293,\n",
      "    \"LABEL_294\": 294,\n",
      "    \"LABEL_295\": 295,\n",
      "    \"LABEL_296\": 296,\n",
      "    \"LABEL_297\": 297,\n",
      "    \"LABEL_298\": 298,\n",
      "    \"LABEL_299\": 299,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_300\": 300,\n",
      "    \"LABEL_301\": 301,\n",
      "    \"LABEL_302\": 302,\n",
      "    \"LABEL_303\": 303,\n",
      "    \"LABEL_304\": 304,\n",
      "    \"LABEL_305\": 305,\n",
      "    \"LABEL_306\": 306,\n",
      "    \"LABEL_307\": 307,\n",
      "    \"LABEL_308\": 308,\n",
      "    \"LABEL_309\": 309,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_310\": 310,\n",
      "    \"LABEL_311\": 311,\n",
      "    \"LABEL_312\": 312,\n",
      "    \"LABEL_313\": 313,\n",
      "    \"LABEL_314\": 314,\n",
      "    \"LABEL_315\": 315,\n",
      "    \"LABEL_316\": 316,\n",
      "    \"LABEL_317\": 317,\n",
      "    \"LABEL_318\": 318,\n",
      "    \"LABEL_319\": 319,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_320\": 320,\n",
      "    \"LABEL_321\": 321,\n",
      "    \"LABEL_322\": 322,\n",
      "    \"LABEL_323\": 323,\n",
      "    \"LABEL_324\": 324,\n",
      "    \"LABEL_325\": 325,\n",
      "    \"LABEL_326\": 326,\n",
      "    \"LABEL_327\": 327,\n",
      "    \"LABEL_328\": 328,\n",
      "    \"LABEL_329\": 329,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_330\": 330,\n",
      "    \"LABEL_331\": 331,\n",
      "    \"LABEL_332\": 332,\n",
      "    \"LABEL_333\": 333,\n",
      "    \"LABEL_334\": 334,\n",
      "    \"LABEL_335\": 335,\n",
      "    \"LABEL_336\": 336,\n",
      "    \"LABEL_337\": 337,\n",
      "    \"LABEL_338\": 338,\n",
      "    \"LABEL_339\": 339,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_340\": 340,\n",
      "    \"LABEL_341\": 341,\n",
      "    \"LABEL_342\": 342,\n",
      "    \"LABEL_343\": 343,\n",
      "    \"LABEL_344\": 344,\n",
      "    \"LABEL_345\": 345,\n",
      "    \"LABEL_346\": 346,\n",
      "    \"LABEL_347\": 347,\n",
      "    \"LABEL_348\": 348,\n",
      "    \"LABEL_349\": 349,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_350\": 350,\n",
      "    \"LABEL_351\": 351,\n",
      "    \"LABEL_352\": 352,\n",
      "    \"LABEL_353\": 353,\n",
      "    \"LABEL_354\": 354,\n",
      "    \"LABEL_355\": 355,\n",
      "    \"LABEL_356\": 356,\n",
      "    \"LABEL_357\": 357,\n",
      "    \"LABEL_358\": 358,\n",
      "    \"LABEL_359\": 359,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_360\": 360,\n",
      "    \"LABEL_361\": 361,\n",
      "    \"LABEL_362\": 362,\n",
      "    \"LABEL_363\": 363,\n",
      "    \"LABEL_364\": 364,\n",
      "    \"LABEL_365\": 365,\n",
      "    \"LABEL_366\": 366,\n",
      "    \"LABEL_367\": 367,\n",
      "    \"LABEL_368\": 368,\n",
      "    \"LABEL_369\": 369,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_370\": 370,\n",
      "    \"LABEL_371\": 371,\n",
      "    \"LABEL_372\": 372,\n",
      "    \"LABEL_373\": 373,\n",
      "    \"LABEL_374\": 374,\n",
      "    \"LABEL_375\": 375,\n",
      "    \"LABEL_376\": 376,\n",
      "    \"LABEL_377\": 377,\n",
      "    \"LABEL_378\": 378,\n",
      "    \"LABEL_379\": 379,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_380\": 380,\n",
      "    \"LABEL_381\": 381,\n",
      "    \"LABEL_382\": 382,\n",
      "    \"LABEL_383\": 383,\n",
      "    \"LABEL_384\": 384,\n",
      "    \"LABEL_385\": 385,\n",
      "    \"LABEL_386\": 386,\n",
      "    \"LABEL_387\": 387,\n",
      "    \"LABEL_388\": 388,\n",
      "    \"LABEL_389\": 389,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_390\": 390,\n",
      "    \"LABEL_391\": 391,\n",
      "    \"LABEL_392\": 392,\n",
      "    \"LABEL_393\": 393,\n",
      "    \"LABEL_394\": 394,\n",
      "    \"LABEL_395\": 395,\n",
      "    \"LABEL_396\": 396,\n",
      "    \"LABEL_397\": 397,\n",
      "    \"LABEL_398\": 398,\n",
      "    \"LABEL_399\": 399,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda72114f8a1458db9f6cbc1bd609693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2ea5a898a74a46b40f98a10b2bfe15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09992ec6cb42bd8d7a2affc8595f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/users1/knupleun/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 28168\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 28168\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3458\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3513\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1150' max='8810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1150/8810 1:03:55 < 7:06:31, 0.30 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.975294</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.002562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.945628</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.903123</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.005693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.867774</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.858038</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.847834</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.839683</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.835363</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.831588</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.832841</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.826643</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.823101</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.822124</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.814368</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.811515</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.005693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.811218</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.810970</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.813659</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.810379</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.806151</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.808063</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.803836</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.797877</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.797956</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.004270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.786033</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.007116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.786061</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.802559</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.767792</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.782248</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.754858</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.008255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.734827</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.717106</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.007686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.702197</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>0.009109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.673756</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.010248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.651907</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.008824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.639291</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.635065</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.011956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.607042</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>5.847000</td>\n",
       "      <td>5.606552</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.010532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.586497</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.576864</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.011671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.567481</td>\n",
       "      <td>0.017079</td>\n",
       "      <td>0.017079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.554890</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.015087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.553756</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.010248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.538824</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>5.729500</td>\n",
       "      <td>5.542026</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.012240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-1000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-1000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3513\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/checkpoint-1000 (score: 0.013378878451465983).\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3458\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='217' max='217' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [217/217 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8287a49135425cad52d5c28af8b94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\",\n",
      "    \"133\": \"LABEL_133\",\n",
      "    \"134\": \"LABEL_134\",\n",
      "    \"135\": \"LABEL_135\",\n",
      "    \"136\": \"LABEL_136\",\n",
      "    \"137\": \"LABEL_137\",\n",
      "    \"138\": \"LABEL_138\",\n",
      "    \"139\": \"LABEL_139\",\n",
      "    \"140\": \"LABEL_140\",\n",
      "    \"141\": \"LABEL_141\",\n",
      "    \"142\": \"LABEL_142\",\n",
      "    \"143\": \"LABEL_143\",\n",
      "    \"144\": \"LABEL_144\",\n",
      "    \"145\": \"LABEL_145\",\n",
      "    \"146\": \"LABEL_146\",\n",
      "    \"147\": \"LABEL_147\",\n",
      "    \"148\": \"LABEL_148\",\n",
      "    \"149\": \"LABEL_149\",\n",
      "    \"150\": \"LABEL_150\",\n",
      "    \"151\": \"LABEL_151\",\n",
      "    \"152\": \"LABEL_152\",\n",
      "    \"153\": \"LABEL_153\",\n",
      "    \"154\": \"LABEL_154\",\n",
      "    \"155\": \"LABEL_155\",\n",
      "    \"156\": \"LABEL_156\",\n",
      "    \"157\": \"LABEL_157\",\n",
      "    \"158\": \"LABEL_158\",\n",
      "    \"159\": \"LABEL_159\",\n",
      "    \"160\": \"LABEL_160\",\n",
      "    \"161\": \"LABEL_161\",\n",
      "    \"162\": \"LABEL_162\",\n",
      "    \"163\": \"LABEL_163\",\n",
      "    \"164\": \"LABEL_164\",\n",
      "    \"165\": \"LABEL_165\",\n",
      "    \"166\": \"LABEL_166\",\n",
      "    \"167\": \"LABEL_167\",\n",
      "    \"168\": \"LABEL_168\",\n",
      "    \"169\": \"LABEL_169\",\n",
      "    \"170\": \"LABEL_170\",\n",
      "    \"171\": \"LABEL_171\",\n",
      "    \"172\": \"LABEL_172\",\n",
      "    \"173\": \"LABEL_173\",\n",
      "    \"174\": \"LABEL_174\",\n",
      "    \"175\": \"LABEL_175\",\n",
      "    \"176\": \"LABEL_176\",\n",
      "    \"177\": \"LABEL_177\",\n",
      "    \"178\": \"LABEL_178\",\n",
      "    \"179\": \"LABEL_179\",\n",
      "    \"180\": \"LABEL_180\",\n",
      "    \"181\": \"LABEL_181\",\n",
      "    \"182\": \"LABEL_182\",\n",
      "    \"183\": \"LABEL_183\",\n",
      "    \"184\": \"LABEL_184\",\n",
      "    \"185\": \"LABEL_185\",\n",
      "    \"186\": \"LABEL_186\",\n",
      "    \"187\": \"LABEL_187\",\n",
      "    \"188\": \"LABEL_188\",\n",
      "    \"189\": \"LABEL_189\",\n",
      "    \"190\": \"LABEL_190\",\n",
      "    \"191\": \"LABEL_191\",\n",
      "    \"192\": \"LABEL_192\",\n",
      "    \"193\": \"LABEL_193\",\n",
      "    \"194\": \"LABEL_194\",\n",
      "    \"195\": \"LABEL_195\",\n",
      "    \"196\": \"LABEL_196\",\n",
      "    \"197\": \"LABEL_197\",\n",
      "    \"198\": \"LABEL_198\",\n",
      "    \"199\": \"LABEL_199\",\n",
      "    \"200\": \"LABEL_200\",\n",
      "    \"201\": \"LABEL_201\",\n",
      "    \"202\": \"LABEL_202\",\n",
      "    \"203\": \"LABEL_203\",\n",
      "    \"204\": \"LABEL_204\",\n",
      "    \"205\": \"LABEL_205\",\n",
      "    \"206\": \"LABEL_206\",\n",
      "    \"207\": \"LABEL_207\",\n",
      "    \"208\": \"LABEL_208\",\n",
      "    \"209\": \"LABEL_209\",\n",
      "    \"210\": \"LABEL_210\",\n",
      "    \"211\": \"LABEL_211\",\n",
      "    \"212\": \"LABEL_212\",\n",
      "    \"213\": \"LABEL_213\",\n",
      "    \"214\": \"LABEL_214\",\n",
      "    \"215\": \"LABEL_215\",\n",
      "    \"216\": \"LABEL_216\",\n",
      "    \"217\": \"LABEL_217\",\n",
      "    \"218\": \"LABEL_218\",\n",
      "    \"219\": \"LABEL_219\",\n",
      "    \"220\": \"LABEL_220\",\n",
      "    \"221\": \"LABEL_221\",\n",
      "    \"222\": \"LABEL_222\",\n",
      "    \"223\": \"LABEL_223\",\n",
      "    \"224\": \"LABEL_224\",\n",
      "    \"225\": \"LABEL_225\",\n",
      "    \"226\": \"LABEL_226\",\n",
      "    \"227\": \"LABEL_227\",\n",
      "    \"228\": \"LABEL_228\",\n",
      "    \"229\": \"LABEL_229\",\n",
      "    \"230\": \"LABEL_230\",\n",
      "    \"231\": \"LABEL_231\",\n",
      "    \"232\": \"LABEL_232\",\n",
      "    \"233\": \"LABEL_233\",\n",
      "    \"234\": \"LABEL_234\",\n",
      "    \"235\": \"LABEL_235\",\n",
      "    \"236\": \"LABEL_236\",\n",
      "    \"237\": \"LABEL_237\",\n",
      "    \"238\": \"LABEL_238\",\n",
      "    \"239\": \"LABEL_239\",\n",
      "    \"240\": \"LABEL_240\",\n",
      "    \"241\": \"LABEL_241\",\n",
      "    \"242\": \"LABEL_242\",\n",
      "    \"243\": \"LABEL_243\",\n",
      "    \"244\": \"LABEL_244\",\n",
      "    \"245\": \"LABEL_245\",\n",
      "    \"246\": \"LABEL_246\",\n",
      "    \"247\": \"LABEL_247\",\n",
      "    \"248\": \"LABEL_248\",\n",
      "    \"249\": \"LABEL_249\",\n",
      "    \"250\": \"LABEL_250\",\n",
      "    \"251\": \"LABEL_251\",\n",
      "    \"252\": \"LABEL_252\",\n",
      "    \"253\": \"LABEL_253\",\n",
      "    \"254\": \"LABEL_254\",\n",
      "    \"255\": \"LABEL_255\",\n",
      "    \"256\": \"LABEL_256\",\n",
      "    \"257\": \"LABEL_257\",\n",
      "    \"258\": \"LABEL_258\",\n",
      "    \"259\": \"LABEL_259\",\n",
      "    \"260\": \"LABEL_260\",\n",
      "    \"261\": \"LABEL_261\",\n",
      "    \"262\": \"LABEL_262\",\n",
      "    \"263\": \"LABEL_263\",\n",
      "    \"264\": \"LABEL_264\",\n",
      "    \"265\": \"LABEL_265\",\n",
      "    \"266\": \"LABEL_266\",\n",
      "    \"267\": \"LABEL_267\",\n",
      "    \"268\": \"LABEL_268\",\n",
      "    \"269\": \"LABEL_269\",\n",
      "    \"270\": \"LABEL_270\",\n",
      "    \"271\": \"LABEL_271\",\n",
      "    \"272\": \"LABEL_272\",\n",
      "    \"273\": \"LABEL_273\",\n",
      "    \"274\": \"LABEL_274\",\n",
      "    \"275\": \"LABEL_275\",\n",
      "    \"276\": \"LABEL_276\",\n",
      "    \"277\": \"LABEL_277\",\n",
      "    \"278\": \"LABEL_278\",\n",
      "    \"279\": \"LABEL_279\",\n",
      "    \"280\": \"LABEL_280\",\n",
      "    \"281\": \"LABEL_281\",\n",
      "    \"282\": \"LABEL_282\",\n",
      "    \"283\": \"LABEL_283\",\n",
      "    \"284\": \"LABEL_284\",\n",
      "    \"285\": \"LABEL_285\",\n",
      "    \"286\": \"LABEL_286\",\n",
      "    \"287\": \"LABEL_287\",\n",
      "    \"288\": \"LABEL_288\",\n",
      "    \"289\": \"LABEL_289\",\n",
      "    \"290\": \"LABEL_290\",\n",
      "    \"291\": \"LABEL_291\",\n",
      "    \"292\": \"LABEL_292\",\n",
      "    \"293\": \"LABEL_293\",\n",
      "    \"294\": \"LABEL_294\",\n",
      "    \"295\": \"LABEL_295\",\n",
      "    \"296\": \"LABEL_296\",\n",
      "    \"297\": \"LABEL_297\",\n",
      "    \"298\": \"LABEL_298\",\n",
      "    \"299\": \"LABEL_299\",\n",
      "    \"300\": \"LABEL_300\",\n",
      "    \"301\": \"LABEL_301\",\n",
      "    \"302\": \"LABEL_302\",\n",
      "    \"303\": \"LABEL_303\",\n",
      "    \"304\": \"LABEL_304\",\n",
      "    \"305\": \"LABEL_305\",\n",
      "    \"306\": \"LABEL_306\",\n",
      "    \"307\": \"LABEL_307\",\n",
      "    \"308\": \"LABEL_308\",\n",
      "    \"309\": \"LABEL_309\",\n",
      "    \"310\": \"LABEL_310\",\n",
      "    \"311\": \"LABEL_311\",\n",
      "    \"312\": \"LABEL_312\",\n",
      "    \"313\": \"LABEL_313\",\n",
      "    \"314\": \"LABEL_314\",\n",
      "    \"315\": \"LABEL_315\",\n",
      "    \"316\": \"LABEL_316\",\n",
      "    \"317\": \"LABEL_317\",\n",
      "    \"318\": \"LABEL_318\",\n",
      "    \"319\": \"LABEL_319\",\n",
      "    \"320\": \"LABEL_320\",\n",
      "    \"321\": \"LABEL_321\",\n",
      "    \"322\": \"LABEL_322\",\n",
      "    \"323\": \"LABEL_323\",\n",
      "    \"324\": \"LABEL_324\",\n",
      "    \"325\": \"LABEL_325\",\n",
      "    \"326\": \"LABEL_326\",\n",
      "    \"327\": \"LABEL_327\",\n",
      "    \"328\": \"LABEL_328\",\n",
      "    \"329\": \"LABEL_329\",\n",
      "    \"330\": \"LABEL_330\",\n",
      "    \"331\": \"LABEL_331\",\n",
      "    \"332\": \"LABEL_332\",\n",
      "    \"333\": \"LABEL_333\",\n",
      "    \"334\": \"LABEL_334\",\n",
      "    \"335\": \"LABEL_335\",\n",
      "    \"336\": \"LABEL_336\",\n",
      "    \"337\": \"LABEL_337\",\n",
      "    \"338\": \"LABEL_338\",\n",
      "    \"339\": \"LABEL_339\",\n",
      "    \"340\": \"LABEL_340\",\n",
      "    \"341\": \"LABEL_341\",\n",
      "    \"342\": \"LABEL_342\",\n",
      "    \"343\": \"LABEL_343\",\n",
      "    \"344\": \"LABEL_344\",\n",
      "    \"345\": \"LABEL_345\",\n",
      "    \"346\": \"LABEL_346\",\n",
      "    \"347\": \"LABEL_347\",\n",
      "    \"348\": \"LABEL_348\",\n",
      "    \"349\": \"LABEL_349\",\n",
      "    \"350\": \"LABEL_350\",\n",
      "    \"351\": \"LABEL_351\",\n",
      "    \"352\": \"LABEL_352\",\n",
      "    \"353\": \"LABEL_353\",\n",
      "    \"354\": \"LABEL_354\",\n",
      "    \"355\": \"LABEL_355\",\n",
      "    \"356\": \"LABEL_356\",\n",
      "    \"357\": \"LABEL_357\",\n",
      "    \"358\": \"LABEL_358\",\n",
      "    \"359\": \"LABEL_359\",\n",
      "    \"360\": \"LABEL_360\",\n",
      "    \"361\": \"LABEL_361\",\n",
      "    \"362\": \"LABEL_362\",\n",
      "    \"363\": \"LABEL_363\",\n",
      "    \"364\": \"LABEL_364\",\n",
      "    \"365\": \"LABEL_365\",\n",
      "    \"366\": \"LABEL_366\",\n",
      "    \"367\": \"LABEL_367\",\n",
      "    \"368\": \"LABEL_368\",\n",
      "    \"369\": \"LABEL_369\",\n",
      "    \"370\": \"LABEL_370\",\n",
      "    \"371\": \"LABEL_371\",\n",
      "    \"372\": \"LABEL_372\",\n",
      "    \"373\": \"LABEL_373\",\n",
      "    \"374\": \"LABEL_374\",\n",
      "    \"375\": \"LABEL_375\",\n",
      "    \"376\": \"LABEL_376\",\n",
      "    \"377\": \"LABEL_377\",\n",
      "    \"378\": \"LABEL_378\",\n",
      "    \"379\": \"LABEL_379\",\n",
      "    \"380\": \"LABEL_380\",\n",
      "    \"381\": \"LABEL_381\",\n",
      "    \"382\": \"LABEL_382\",\n",
      "    \"383\": \"LABEL_383\",\n",
      "    \"384\": \"LABEL_384\",\n",
      "    \"385\": \"LABEL_385\",\n",
      "    \"386\": \"LABEL_386\",\n",
      "    \"387\": \"LABEL_387\",\n",
      "    \"388\": \"LABEL_388\",\n",
      "    \"389\": \"LABEL_389\",\n",
      "    \"390\": \"LABEL_390\",\n",
      "    \"391\": \"LABEL_391\",\n",
      "    \"392\": \"LABEL_392\",\n",
      "    \"393\": \"LABEL_393\",\n",
      "    \"394\": \"LABEL_394\",\n",
      "    \"395\": \"LABEL_395\",\n",
      "    \"396\": \"LABEL_396\",\n",
      "    \"397\": \"LABEL_397\",\n",
      "    \"398\": \"LABEL_398\",\n",
      "    \"399\": \"LABEL_399\",\n",
      "    \"400\": \"LABEL_400\",\n",
      "    \"401\": \"LABEL_401\",\n",
      "    \"402\": \"LABEL_402\",\n",
      "    \"403\": \"LABEL_403\",\n",
      "    \"404\": \"LABEL_404\",\n",
      "    \"405\": \"LABEL_405\",\n",
      "    \"406\": \"LABEL_406\",\n",
      "    \"407\": \"LABEL_407\",\n",
      "    \"408\": \"LABEL_408\",\n",
      "    \"409\": \"LABEL_409\",\n",
      "    \"410\": \"LABEL_410\",\n",
      "    \"411\": \"LABEL_411\",\n",
      "    \"412\": \"LABEL_412\",\n",
      "    \"413\": \"LABEL_413\",\n",
      "    \"414\": \"LABEL_414\",\n",
      "    \"415\": \"LABEL_415\",\n",
      "    \"416\": \"LABEL_416\",\n",
      "    \"417\": \"LABEL_417\",\n",
      "    \"418\": \"LABEL_418\",\n",
      "    \"419\": \"LABEL_419\",\n",
      "    \"420\": \"LABEL_420\",\n",
      "    \"421\": \"LABEL_421\",\n",
      "    \"422\": \"LABEL_422\",\n",
      "    \"423\": \"LABEL_423\",\n",
      "    \"424\": \"LABEL_424\",\n",
      "    \"425\": \"LABEL_425\",\n",
      "    \"426\": \"LABEL_426\",\n",
      "    \"427\": \"LABEL_427\",\n",
      "    \"428\": \"LABEL_428\",\n",
      "    \"429\": \"LABEL_429\",\n",
      "    \"430\": \"LABEL_430\",\n",
      "    \"431\": \"LABEL_431\",\n",
      "    \"432\": \"LABEL_432\",\n",
      "    \"433\": \"LABEL_433\",\n",
      "    \"434\": \"LABEL_434\",\n",
      "    \"435\": \"LABEL_435\",\n",
      "    \"436\": \"LABEL_436\",\n",
      "    \"437\": \"LABEL_437\",\n",
      "    \"438\": \"LABEL_438\",\n",
      "    \"439\": \"LABEL_439\",\n",
      "    \"440\": \"LABEL_440\",\n",
      "    \"441\": \"LABEL_441\",\n",
      "    \"442\": \"LABEL_442\",\n",
      "    \"443\": \"LABEL_443\",\n",
      "    \"444\": \"LABEL_444\",\n",
      "    \"445\": \"LABEL_445\",\n",
      "    \"446\": \"LABEL_446\",\n",
      "    \"447\": \"LABEL_447\",\n",
      "    \"448\": \"LABEL_448\",\n",
      "    \"449\": \"LABEL_449\",\n",
      "    \"450\": \"LABEL_450\",\n",
      "    \"451\": \"LABEL_451\",\n",
      "    \"452\": \"LABEL_452\",\n",
      "    \"453\": \"LABEL_453\",\n",
      "    \"454\": \"LABEL_454\",\n",
      "    \"455\": \"LABEL_455\",\n",
      "    \"456\": \"LABEL_456\",\n",
      "    \"457\": \"LABEL_457\",\n",
      "    \"458\": \"LABEL_458\",\n",
      "    \"459\": \"LABEL_459\",\n",
      "    \"460\": \"LABEL_460\",\n",
      "    \"461\": \"LABEL_461\",\n",
      "    \"462\": \"LABEL_462\",\n",
      "    \"463\": \"LABEL_463\",\n",
      "    \"464\": \"LABEL_464\",\n",
      "    \"465\": \"LABEL_465\",\n",
      "    \"466\": \"LABEL_466\",\n",
      "    \"467\": \"LABEL_467\",\n",
      "    \"468\": \"LABEL_468\",\n",
      "    \"469\": \"LABEL_469\",\n",
      "    \"470\": \"LABEL_470\",\n",
      "    \"471\": \"LABEL_471\",\n",
      "    \"472\": \"LABEL_472\",\n",
      "    \"473\": \"LABEL_473\",\n",
      "    \"474\": \"LABEL_474\",\n",
      "    \"475\": \"LABEL_475\",\n",
      "    \"476\": \"LABEL_476\",\n",
      "    \"477\": \"LABEL_477\",\n",
      "    \"478\": \"LABEL_478\",\n",
      "    \"479\": \"LABEL_479\",\n",
      "    \"480\": \"LABEL_480\",\n",
      "    \"481\": \"LABEL_481\",\n",
      "    \"482\": \"LABEL_482\",\n",
      "    \"483\": \"LABEL_483\",\n",
      "    \"484\": \"LABEL_484\",\n",
      "    \"485\": \"LABEL_485\",\n",
      "    \"486\": \"LABEL_486\",\n",
      "    \"487\": \"LABEL_487\",\n",
      "    \"488\": \"LABEL_488\",\n",
      "    \"489\": \"LABEL_489\",\n",
      "    \"490\": \"LABEL_490\",\n",
      "    \"491\": \"LABEL_491\",\n",
      "    \"492\": \"LABEL_492\",\n",
      "    \"493\": \"LABEL_493\",\n",
      "    \"494\": \"LABEL_494\",\n",
      "    \"495\": \"LABEL_495\",\n",
      "    \"496\": \"LABEL_496\",\n",
      "    \"497\": \"LABEL_497\",\n",
      "    \"498\": \"LABEL_498\",\n",
      "    \"499\": \"LABEL_499\",\n",
      "    \"500\": \"LABEL_500\",\n",
      "    \"501\": \"LABEL_501\",\n",
      "    \"502\": \"LABEL_502\",\n",
      "    \"503\": \"LABEL_503\",\n",
      "    \"504\": \"LABEL_504\",\n",
      "    \"505\": \"LABEL_505\",\n",
      "    \"506\": \"LABEL_506\",\n",
      "    \"507\": \"LABEL_507\",\n",
      "    \"508\": \"LABEL_508\",\n",
      "    \"509\": \"LABEL_509\",\n",
      "    \"510\": \"LABEL_510\",\n",
      "    \"511\": \"LABEL_511\",\n",
      "    \"512\": \"LABEL_512\",\n",
      "    \"513\": \"LABEL_513\",\n",
      "    \"514\": \"LABEL_514\",\n",
      "    \"515\": \"LABEL_515\",\n",
      "    \"516\": \"LABEL_516\",\n",
      "    \"517\": \"LABEL_517\",\n",
      "    \"518\": \"LABEL_518\",\n",
      "    \"519\": \"LABEL_519\",\n",
      "    \"520\": \"LABEL_520\",\n",
      "    \"521\": \"LABEL_521\",\n",
      "    \"522\": \"LABEL_522\",\n",
      "    \"523\": \"LABEL_523\",\n",
      "    \"524\": \"LABEL_524\",\n",
      "    \"525\": \"LABEL_525\",\n",
      "    \"526\": \"LABEL_526\",\n",
      "    \"527\": \"LABEL_527\",\n",
      "    \"528\": \"LABEL_528\",\n",
      "    \"529\": \"LABEL_529\",\n",
      "    \"530\": \"LABEL_530\",\n",
      "    \"531\": \"LABEL_531\",\n",
      "    \"532\": \"LABEL_532\",\n",
      "    \"533\": \"LABEL_533\",\n",
      "    \"534\": \"LABEL_534\",\n",
      "    \"535\": \"LABEL_535\",\n",
      "    \"536\": \"LABEL_536\",\n",
      "    \"537\": \"LABEL_537\",\n",
      "    \"538\": \"LABEL_538\",\n",
      "    \"539\": \"LABEL_539\",\n",
      "    \"540\": \"LABEL_540\",\n",
      "    \"541\": \"LABEL_541\",\n",
      "    \"542\": \"LABEL_542\",\n",
      "    \"543\": \"LABEL_543\",\n",
      "    \"544\": \"LABEL_544\",\n",
      "    \"545\": \"LABEL_545\",\n",
      "    \"546\": \"LABEL_546\",\n",
      "    \"547\": \"LABEL_547\",\n",
      "    \"548\": \"LABEL_548\",\n",
      "    \"549\": \"LABEL_549\",\n",
      "    \"550\": \"LABEL_550\",\n",
      "    \"551\": \"LABEL_551\",\n",
      "    \"552\": \"LABEL_552\",\n",
      "    \"553\": \"LABEL_553\",\n",
      "    \"554\": \"LABEL_554\",\n",
      "    \"555\": \"LABEL_555\",\n",
      "    \"556\": \"LABEL_556\",\n",
      "    \"557\": \"LABEL_557\",\n",
      "    \"558\": \"LABEL_558\",\n",
      "    \"559\": \"LABEL_559\",\n",
      "    \"560\": \"LABEL_560\",\n",
      "    \"561\": \"LABEL_561\",\n",
      "    \"562\": \"LABEL_562\",\n",
      "    \"563\": \"LABEL_563\",\n",
      "    \"564\": \"LABEL_564\",\n",
      "    \"565\": \"LABEL_565\",\n",
      "    \"566\": \"LABEL_566\",\n",
      "    \"567\": \"LABEL_567\",\n",
      "    \"568\": \"LABEL_568\",\n",
      "    \"569\": \"LABEL_569\",\n",
      "    \"570\": \"LABEL_570\",\n",
      "    \"571\": \"LABEL_571\",\n",
      "    \"572\": \"LABEL_572\",\n",
      "    \"573\": \"LABEL_573\",\n",
      "    \"574\": \"LABEL_574\",\n",
      "    \"575\": \"LABEL_575\",\n",
      "    \"576\": \"LABEL_576\",\n",
      "    \"577\": \"LABEL_577\",\n",
      "    \"578\": \"LABEL_578\",\n",
      "    \"579\": \"LABEL_579\",\n",
      "    \"580\": \"LABEL_580\",\n",
      "    \"581\": \"LABEL_581\",\n",
      "    \"582\": \"LABEL_582\",\n",
      "    \"583\": \"LABEL_583\",\n",
      "    \"584\": \"LABEL_584\",\n",
      "    \"585\": \"LABEL_585\",\n",
      "    \"586\": \"LABEL_586\",\n",
      "    \"587\": \"LABEL_587\",\n",
      "    \"588\": \"LABEL_588\",\n",
      "    \"589\": \"LABEL_589\",\n",
      "    \"590\": \"LABEL_590\",\n",
      "    \"591\": \"LABEL_591\",\n",
      "    \"592\": \"LABEL_592\",\n",
      "    \"593\": \"LABEL_593\",\n",
      "    \"594\": \"LABEL_594\",\n",
      "    \"595\": \"LABEL_595\",\n",
      "    \"596\": \"LABEL_596\",\n",
      "    \"597\": \"LABEL_597\",\n",
      "    \"598\": \"LABEL_598\",\n",
      "    \"599\": \"LABEL_599\",\n",
      "    \"600\": \"LABEL_600\",\n",
      "    \"601\": \"LABEL_601\",\n",
      "    \"602\": \"LABEL_602\",\n",
      "    \"603\": \"LABEL_603\",\n",
      "    \"604\": \"LABEL_604\",\n",
      "    \"605\": \"LABEL_605\",\n",
      "    \"606\": \"LABEL_606\",\n",
      "    \"607\": \"LABEL_607\",\n",
      "    \"608\": \"LABEL_608\",\n",
      "    \"609\": \"LABEL_609\",\n",
      "    \"610\": \"LABEL_610\",\n",
      "    \"611\": \"LABEL_611\",\n",
      "    \"612\": \"LABEL_612\",\n",
      "    \"613\": \"LABEL_613\",\n",
      "    \"614\": \"LABEL_614\",\n",
      "    \"615\": \"LABEL_615\",\n",
      "    \"616\": \"LABEL_616\",\n",
      "    \"617\": \"LABEL_617\",\n",
      "    \"618\": \"LABEL_618\",\n",
      "    \"619\": \"LABEL_619\",\n",
      "    \"620\": \"LABEL_620\",\n",
      "    \"621\": \"LABEL_621\",\n",
      "    \"622\": \"LABEL_622\",\n",
      "    \"623\": \"LABEL_623\",\n",
      "    \"624\": \"LABEL_624\",\n",
      "    \"625\": \"LABEL_625\",\n",
      "    \"626\": \"LABEL_626\",\n",
      "    \"627\": \"LABEL_627\",\n",
      "    \"628\": \"LABEL_628\",\n",
      "    \"629\": \"LABEL_629\",\n",
      "    \"630\": \"LABEL_630\",\n",
      "    \"631\": \"LABEL_631\",\n",
      "    \"632\": \"LABEL_632\",\n",
      "    \"633\": \"LABEL_633\",\n",
      "    \"634\": \"LABEL_634\",\n",
      "    \"635\": \"LABEL_635\",\n",
      "    \"636\": \"LABEL_636\",\n",
      "    \"637\": \"LABEL_637\",\n",
      "    \"638\": \"LABEL_638\",\n",
      "    \"639\": \"LABEL_639\",\n",
      "    \"640\": \"LABEL_640\",\n",
      "    \"641\": \"LABEL_641\",\n",
      "    \"642\": \"LABEL_642\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_133\": 133,\n",
      "    \"LABEL_134\": 134,\n",
      "    \"LABEL_135\": 135,\n",
      "    \"LABEL_136\": 136,\n",
      "    \"LABEL_137\": 137,\n",
      "    \"LABEL_138\": 138,\n",
      "    \"LABEL_139\": 139,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_140\": 140,\n",
      "    \"LABEL_141\": 141,\n",
      "    \"LABEL_142\": 142,\n",
      "    \"LABEL_143\": 143,\n",
      "    \"LABEL_144\": 144,\n",
      "    \"LABEL_145\": 145,\n",
      "    \"LABEL_146\": 146,\n",
      "    \"LABEL_147\": 147,\n",
      "    \"LABEL_148\": 148,\n",
      "    \"LABEL_149\": 149,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_150\": 150,\n",
      "    \"LABEL_151\": 151,\n",
      "    \"LABEL_152\": 152,\n",
      "    \"LABEL_153\": 153,\n",
      "    \"LABEL_154\": 154,\n",
      "    \"LABEL_155\": 155,\n",
      "    \"LABEL_156\": 156,\n",
      "    \"LABEL_157\": 157,\n",
      "    \"LABEL_158\": 158,\n",
      "    \"LABEL_159\": 159,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_160\": 160,\n",
      "    \"LABEL_161\": 161,\n",
      "    \"LABEL_162\": 162,\n",
      "    \"LABEL_163\": 163,\n",
      "    \"LABEL_164\": 164,\n",
      "    \"LABEL_165\": 165,\n",
      "    \"LABEL_166\": 166,\n",
      "    \"LABEL_167\": 167,\n",
      "    \"LABEL_168\": 168,\n",
      "    \"LABEL_169\": 169,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_170\": 170,\n",
      "    \"LABEL_171\": 171,\n",
      "    \"LABEL_172\": 172,\n",
      "    \"LABEL_173\": 173,\n",
      "    \"LABEL_174\": 174,\n",
      "    \"LABEL_175\": 175,\n",
      "    \"LABEL_176\": 176,\n",
      "    \"LABEL_177\": 177,\n",
      "    \"LABEL_178\": 178,\n",
      "    \"LABEL_179\": 179,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_180\": 180,\n",
      "    \"LABEL_181\": 181,\n",
      "    \"LABEL_182\": 182,\n",
      "    \"LABEL_183\": 183,\n",
      "    \"LABEL_184\": 184,\n",
      "    \"LABEL_185\": 185,\n",
      "    \"LABEL_186\": 186,\n",
      "    \"LABEL_187\": 187,\n",
      "    \"LABEL_188\": 188,\n",
      "    \"LABEL_189\": 189,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_190\": 190,\n",
      "    \"LABEL_191\": 191,\n",
      "    \"LABEL_192\": 192,\n",
      "    \"LABEL_193\": 193,\n",
      "    \"LABEL_194\": 194,\n",
      "    \"LABEL_195\": 195,\n",
      "    \"LABEL_196\": 196,\n",
      "    \"LABEL_197\": 197,\n",
      "    \"LABEL_198\": 198,\n",
      "    \"LABEL_199\": 199,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_200\": 200,\n",
      "    \"LABEL_201\": 201,\n",
      "    \"LABEL_202\": 202,\n",
      "    \"LABEL_203\": 203,\n",
      "    \"LABEL_204\": 204,\n",
      "    \"LABEL_205\": 205,\n",
      "    \"LABEL_206\": 206,\n",
      "    \"LABEL_207\": 207,\n",
      "    \"LABEL_208\": 208,\n",
      "    \"LABEL_209\": 209,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_210\": 210,\n",
      "    \"LABEL_211\": 211,\n",
      "    \"LABEL_212\": 212,\n",
      "    \"LABEL_213\": 213,\n",
      "    \"LABEL_214\": 214,\n",
      "    \"LABEL_215\": 215,\n",
      "    \"LABEL_216\": 216,\n",
      "    \"LABEL_217\": 217,\n",
      "    \"LABEL_218\": 218,\n",
      "    \"LABEL_219\": 219,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_220\": 220,\n",
      "    \"LABEL_221\": 221,\n",
      "    \"LABEL_222\": 222,\n",
      "    \"LABEL_223\": 223,\n",
      "    \"LABEL_224\": 224,\n",
      "    \"LABEL_225\": 225,\n",
      "    \"LABEL_226\": 226,\n",
      "    \"LABEL_227\": 227,\n",
      "    \"LABEL_228\": 228,\n",
      "    \"LABEL_229\": 229,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_230\": 230,\n",
      "    \"LABEL_231\": 231,\n",
      "    \"LABEL_232\": 232,\n",
      "    \"LABEL_233\": 233,\n",
      "    \"LABEL_234\": 234,\n",
      "    \"LABEL_235\": 235,\n",
      "    \"LABEL_236\": 236,\n",
      "    \"LABEL_237\": 237,\n",
      "    \"LABEL_238\": 238,\n",
      "    \"LABEL_239\": 239,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_240\": 240,\n",
      "    \"LABEL_241\": 241,\n",
      "    \"LABEL_242\": 242,\n",
      "    \"LABEL_243\": 243,\n",
      "    \"LABEL_244\": 244,\n",
      "    \"LABEL_245\": 245,\n",
      "    \"LABEL_246\": 246,\n",
      "    \"LABEL_247\": 247,\n",
      "    \"LABEL_248\": 248,\n",
      "    \"LABEL_249\": 249,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_250\": 250,\n",
      "    \"LABEL_251\": 251,\n",
      "    \"LABEL_252\": 252,\n",
      "    \"LABEL_253\": 253,\n",
      "    \"LABEL_254\": 254,\n",
      "    \"LABEL_255\": 255,\n",
      "    \"LABEL_256\": 256,\n",
      "    \"LABEL_257\": 257,\n",
      "    \"LABEL_258\": 258,\n",
      "    \"LABEL_259\": 259,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_260\": 260,\n",
      "    \"LABEL_261\": 261,\n",
      "    \"LABEL_262\": 262,\n",
      "    \"LABEL_263\": 263,\n",
      "    \"LABEL_264\": 264,\n",
      "    \"LABEL_265\": 265,\n",
      "    \"LABEL_266\": 266,\n",
      "    \"LABEL_267\": 267,\n",
      "    \"LABEL_268\": 268,\n",
      "    \"LABEL_269\": 269,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_270\": 270,\n",
      "    \"LABEL_271\": 271,\n",
      "    \"LABEL_272\": 272,\n",
      "    \"LABEL_273\": 273,\n",
      "    \"LABEL_274\": 274,\n",
      "    \"LABEL_275\": 275,\n",
      "    \"LABEL_276\": 276,\n",
      "    \"LABEL_277\": 277,\n",
      "    \"LABEL_278\": 278,\n",
      "    \"LABEL_279\": 279,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_280\": 280,\n",
      "    \"LABEL_281\": 281,\n",
      "    \"LABEL_282\": 282,\n",
      "    \"LABEL_283\": 283,\n",
      "    \"LABEL_284\": 284,\n",
      "    \"LABEL_285\": 285,\n",
      "    \"LABEL_286\": 286,\n",
      "    \"LABEL_287\": 287,\n",
      "    \"LABEL_288\": 288,\n",
      "    \"LABEL_289\": 289,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_290\": 290,\n",
      "    \"LABEL_291\": 291,\n",
      "    \"LABEL_292\": 292,\n",
      "    \"LABEL_293\": 293,\n",
      "    \"LABEL_294\": 294,\n",
      "    \"LABEL_295\": 295,\n",
      "    \"LABEL_296\": 296,\n",
      "    \"LABEL_297\": 297,\n",
      "    \"LABEL_298\": 298,\n",
      "    \"LABEL_299\": 299,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_300\": 300,\n",
      "    \"LABEL_301\": 301,\n",
      "    \"LABEL_302\": 302,\n",
      "    \"LABEL_303\": 303,\n",
      "    \"LABEL_304\": 304,\n",
      "    \"LABEL_305\": 305,\n",
      "    \"LABEL_306\": 306,\n",
      "    \"LABEL_307\": 307,\n",
      "    \"LABEL_308\": 308,\n",
      "    \"LABEL_309\": 309,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_310\": 310,\n",
      "    \"LABEL_311\": 311,\n",
      "    \"LABEL_312\": 312,\n",
      "    \"LABEL_313\": 313,\n",
      "    \"LABEL_314\": 314,\n",
      "    \"LABEL_315\": 315,\n",
      "    \"LABEL_316\": 316,\n",
      "    \"LABEL_317\": 317,\n",
      "    \"LABEL_318\": 318,\n",
      "    \"LABEL_319\": 319,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_320\": 320,\n",
      "    \"LABEL_321\": 321,\n",
      "    \"LABEL_322\": 322,\n",
      "    \"LABEL_323\": 323,\n",
      "    \"LABEL_324\": 324,\n",
      "    \"LABEL_325\": 325,\n",
      "    \"LABEL_326\": 326,\n",
      "    \"LABEL_327\": 327,\n",
      "    \"LABEL_328\": 328,\n",
      "    \"LABEL_329\": 329,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_330\": 330,\n",
      "    \"LABEL_331\": 331,\n",
      "    \"LABEL_332\": 332,\n",
      "    \"LABEL_333\": 333,\n",
      "    \"LABEL_334\": 334,\n",
      "    \"LABEL_335\": 335,\n",
      "    \"LABEL_336\": 336,\n",
      "    \"LABEL_337\": 337,\n",
      "    \"LABEL_338\": 338,\n",
      "    \"LABEL_339\": 339,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_340\": 340,\n",
      "    \"LABEL_341\": 341,\n",
      "    \"LABEL_342\": 342,\n",
      "    \"LABEL_343\": 343,\n",
      "    \"LABEL_344\": 344,\n",
      "    \"LABEL_345\": 345,\n",
      "    \"LABEL_346\": 346,\n",
      "    \"LABEL_347\": 347,\n",
      "    \"LABEL_348\": 348,\n",
      "    \"LABEL_349\": 349,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_350\": 350,\n",
      "    \"LABEL_351\": 351,\n",
      "    \"LABEL_352\": 352,\n",
      "    \"LABEL_353\": 353,\n",
      "    \"LABEL_354\": 354,\n",
      "    \"LABEL_355\": 355,\n",
      "    \"LABEL_356\": 356,\n",
      "    \"LABEL_357\": 357,\n",
      "    \"LABEL_358\": 358,\n",
      "    \"LABEL_359\": 359,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_360\": 360,\n",
      "    \"LABEL_361\": 361,\n",
      "    \"LABEL_362\": 362,\n",
      "    \"LABEL_363\": 363,\n",
      "    \"LABEL_364\": 364,\n",
      "    \"LABEL_365\": 365,\n",
      "    \"LABEL_366\": 366,\n",
      "    \"LABEL_367\": 367,\n",
      "    \"LABEL_368\": 368,\n",
      "    \"LABEL_369\": 369,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_370\": 370,\n",
      "    \"LABEL_371\": 371,\n",
      "    \"LABEL_372\": 372,\n",
      "    \"LABEL_373\": 373,\n",
      "    \"LABEL_374\": 374,\n",
      "    \"LABEL_375\": 375,\n",
      "    \"LABEL_376\": 376,\n",
      "    \"LABEL_377\": 377,\n",
      "    \"LABEL_378\": 378,\n",
      "    \"LABEL_379\": 379,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_380\": 380,\n",
      "    \"LABEL_381\": 381,\n",
      "    \"LABEL_382\": 382,\n",
      "    \"LABEL_383\": 383,\n",
      "    \"LABEL_384\": 384,\n",
      "    \"LABEL_385\": 385,\n",
      "    \"LABEL_386\": 386,\n",
      "    \"LABEL_387\": 387,\n",
      "    \"LABEL_388\": 388,\n",
      "    \"LABEL_389\": 389,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_390\": 390,\n",
      "    \"LABEL_391\": 391,\n",
      "    \"LABEL_392\": 392,\n",
      "    \"LABEL_393\": 393,\n",
      "    \"LABEL_394\": 394,\n",
      "    \"LABEL_395\": 395,\n",
      "    \"LABEL_396\": 396,\n",
      "    \"LABEL_397\": 397,\n",
      "    \"LABEL_398\": 398,\n",
      "    \"LABEL_399\": 399,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_400\": 400,\n",
      "    \"LABEL_401\": 401,\n",
      "    \"LABEL_402\": 402,\n",
      "    \"LABEL_403\": 403,\n",
      "    \"LABEL_404\": 404,\n",
      "    \"LABEL_405\": 405,\n",
      "    \"LABEL_406\": 406,\n",
      "    \"LABEL_407\": 407,\n",
      "    \"LABEL_408\": 408,\n",
      "    \"LABEL_409\": 409,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_410\": 410,\n",
      "    \"LABEL_411\": 411,\n",
      "    \"LABEL_412\": 412,\n",
      "    \"LABEL_413\": 413,\n",
      "    \"LABEL_414\": 414,\n",
      "    \"LABEL_415\": 415,\n",
      "    \"LABEL_416\": 416,\n",
      "    \"LABEL_417\": 417,\n",
      "    \"LABEL_418\": 418,\n",
      "    \"LABEL_419\": 419,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_420\": 420,\n",
      "    \"LABEL_421\": 421,\n",
      "    \"LABEL_422\": 422,\n",
      "    \"LABEL_423\": 423,\n",
      "    \"LABEL_424\": 424,\n",
      "    \"LABEL_425\": 425,\n",
      "    \"LABEL_426\": 426,\n",
      "    \"LABEL_427\": 427,\n",
      "    \"LABEL_428\": 428,\n",
      "    \"LABEL_429\": 429,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_430\": 430,\n",
      "    \"LABEL_431\": 431,\n",
      "    \"LABEL_432\": 432,\n",
      "    \"LABEL_433\": 433,\n",
      "    \"LABEL_434\": 434,\n",
      "    \"LABEL_435\": 435,\n",
      "    \"LABEL_436\": 436,\n",
      "    \"LABEL_437\": 437,\n",
      "    \"LABEL_438\": 438,\n",
      "    \"LABEL_439\": 439,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_440\": 440,\n",
      "    \"LABEL_441\": 441,\n",
      "    \"LABEL_442\": 442,\n",
      "    \"LABEL_443\": 443,\n",
      "    \"LABEL_444\": 444,\n",
      "    \"LABEL_445\": 445,\n",
      "    \"LABEL_446\": 446,\n",
      "    \"LABEL_447\": 447,\n",
      "    \"LABEL_448\": 448,\n",
      "    \"LABEL_449\": 449,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_450\": 450,\n",
      "    \"LABEL_451\": 451,\n",
      "    \"LABEL_452\": 452,\n",
      "    \"LABEL_453\": 453,\n",
      "    \"LABEL_454\": 454,\n",
      "    \"LABEL_455\": 455,\n",
      "    \"LABEL_456\": 456,\n",
      "    \"LABEL_457\": 457,\n",
      "    \"LABEL_458\": 458,\n",
      "    \"LABEL_459\": 459,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_460\": 460,\n",
      "    \"LABEL_461\": 461,\n",
      "    \"LABEL_462\": 462,\n",
      "    \"LABEL_463\": 463,\n",
      "    \"LABEL_464\": 464,\n",
      "    \"LABEL_465\": 465,\n",
      "    \"LABEL_466\": 466,\n",
      "    \"LABEL_467\": 467,\n",
      "    \"LABEL_468\": 468,\n",
      "    \"LABEL_469\": 469,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_470\": 470,\n",
      "    \"LABEL_471\": 471,\n",
      "    \"LABEL_472\": 472,\n",
      "    \"LABEL_473\": 473,\n",
      "    \"LABEL_474\": 474,\n",
      "    \"LABEL_475\": 475,\n",
      "    \"LABEL_476\": 476,\n",
      "    \"LABEL_477\": 477,\n",
      "    \"LABEL_478\": 478,\n",
      "    \"LABEL_479\": 479,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_480\": 480,\n",
      "    \"LABEL_481\": 481,\n",
      "    \"LABEL_482\": 482,\n",
      "    \"LABEL_483\": 483,\n",
      "    \"LABEL_484\": 484,\n",
      "    \"LABEL_485\": 485,\n",
      "    \"LABEL_486\": 486,\n",
      "    \"LABEL_487\": 487,\n",
      "    \"LABEL_488\": 488,\n",
      "    \"LABEL_489\": 489,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_490\": 490,\n",
      "    \"LABEL_491\": 491,\n",
      "    \"LABEL_492\": 492,\n",
      "    \"LABEL_493\": 493,\n",
      "    \"LABEL_494\": 494,\n",
      "    \"LABEL_495\": 495,\n",
      "    \"LABEL_496\": 496,\n",
      "    \"LABEL_497\": 497,\n",
      "    \"LABEL_498\": 498,\n",
      "    \"LABEL_499\": 499,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_500\": 500,\n",
      "    \"LABEL_501\": 501,\n",
      "    \"LABEL_502\": 502,\n",
      "    \"LABEL_503\": 503,\n",
      "    \"LABEL_504\": 504,\n",
      "    \"LABEL_505\": 505,\n",
      "    \"LABEL_506\": 506,\n",
      "    \"LABEL_507\": 507,\n",
      "    \"LABEL_508\": 508,\n",
      "    \"LABEL_509\": 509,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_510\": 510,\n",
      "    \"LABEL_511\": 511,\n",
      "    \"LABEL_512\": 512,\n",
      "    \"LABEL_513\": 513,\n",
      "    \"LABEL_514\": 514,\n",
      "    \"LABEL_515\": 515,\n",
      "    \"LABEL_516\": 516,\n",
      "    \"LABEL_517\": 517,\n",
      "    \"LABEL_518\": 518,\n",
      "    \"LABEL_519\": 519,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_520\": 520,\n",
      "    \"LABEL_521\": 521,\n",
      "    \"LABEL_522\": 522,\n",
      "    \"LABEL_523\": 523,\n",
      "    \"LABEL_524\": 524,\n",
      "    \"LABEL_525\": 525,\n",
      "    \"LABEL_526\": 526,\n",
      "    \"LABEL_527\": 527,\n",
      "    \"LABEL_528\": 528,\n",
      "    \"LABEL_529\": 529,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_530\": 530,\n",
      "    \"LABEL_531\": 531,\n",
      "    \"LABEL_532\": 532,\n",
      "    \"LABEL_533\": 533,\n",
      "    \"LABEL_534\": 534,\n",
      "    \"LABEL_535\": 535,\n",
      "    \"LABEL_536\": 536,\n",
      "    \"LABEL_537\": 537,\n",
      "    \"LABEL_538\": 538,\n",
      "    \"LABEL_539\": 539,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_540\": 540,\n",
      "    \"LABEL_541\": 541,\n",
      "    \"LABEL_542\": 542,\n",
      "    \"LABEL_543\": 543,\n",
      "    \"LABEL_544\": 544,\n",
      "    \"LABEL_545\": 545,\n",
      "    \"LABEL_546\": 546,\n",
      "    \"LABEL_547\": 547,\n",
      "    \"LABEL_548\": 548,\n",
      "    \"LABEL_549\": 549,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_550\": 550,\n",
      "    \"LABEL_551\": 551,\n",
      "    \"LABEL_552\": 552,\n",
      "    \"LABEL_553\": 553,\n",
      "    \"LABEL_554\": 554,\n",
      "    \"LABEL_555\": 555,\n",
      "    \"LABEL_556\": 556,\n",
      "    \"LABEL_557\": 557,\n",
      "    \"LABEL_558\": 558,\n",
      "    \"LABEL_559\": 559,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_560\": 560,\n",
      "    \"LABEL_561\": 561,\n",
      "    \"LABEL_562\": 562,\n",
      "    \"LABEL_563\": 563,\n",
      "    \"LABEL_564\": 564,\n",
      "    \"LABEL_565\": 565,\n",
      "    \"LABEL_566\": 566,\n",
      "    \"LABEL_567\": 567,\n",
      "    \"LABEL_568\": 568,\n",
      "    \"LABEL_569\": 569,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_570\": 570,\n",
      "    \"LABEL_571\": 571,\n",
      "    \"LABEL_572\": 572,\n",
      "    \"LABEL_573\": 573,\n",
      "    \"LABEL_574\": 574,\n",
      "    \"LABEL_575\": 575,\n",
      "    \"LABEL_576\": 576,\n",
      "    \"LABEL_577\": 577,\n",
      "    \"LABEL_578\": 578,\n",
      "    \"LABEL_579\": 579,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_580\": 580,\n",
      "    \"LABEL_581\": 581,\n",
      "    \"LABEL_582\": 582,\n",
      "    \"LABEL_583\": 583,\n",
      "    \"LABEL_584\": 584,\n",
      "    \"LABEL_585\": 585,\n",
      "    \"LABEL_586\": 586,\n",
      "    \"LABEL_587\": 587,\n",
      "    \"LABEL_588\": 588,\n",
      "    \"LABEL_589\": 589,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_590\": 590,\n",
      "    \"LABEL_591\": 591,\n",
      "    \"LABEL_592\": 592,\n",
      "    \"LABEL_593\": 593,\n",
      "    \"LABEL_594\": 594,\n",
      "    \"LABEL_595\": 595,\n",
      "    \"LABEL_596\": 596,\n",
      "    \"LABEL_597\": 597,\n",
      "    \"LABEL_598\": 598,\n",
      "    \"LABEL_599\": 599,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_600\": 600,\n",
      "    \"LABEL_601\": 601,\n",
      "    \"LABEL_602\": 602,\n",
      "    \"LABEL_603\": 603,\n",
      "    \"LABEL_604\": 604,\n",
      "    \"LABEL_605\": 605,\n",
      "    \"LABEL_606\": 606,\n",
      "    \"LABEL_607\": 607,\n",
      "    \"LABEL_608\": 608,\n",
      "    \"LABEL_609\": 609,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_610\": 610,\n",
      "    \"LABEL_611\": 611,\n",
      "    \"LABEL_612\": 612,\n",
      "    \"LABEL_613\": 613,\n",
      "    \"LABEL_614\": 614,\n",
      "    \"LABEL_615\": 615,\n",
      "    \"LABEL_616\": 616,\n",
      "    \"LABEL_617\": 617,\n",
      "    \"LABEL_618\": 618,\n",
      "    \"LABEL_619\": 619,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_620\": 620,\n",
      "    \"LABEL_621\": 621,\n",
      "    \"LABEL_622\": 622,\n",
      "    \"LABEL_623\": 623,\n",
      "    \"LABEL_624\": 624,\n",
      "    \"LABEL_625\": 625,\n",
      "    \"LABEL_626\": 626,\n",
      "    \"LABEL_627\": 627,\n",
      "    \"LABEL_628\": 628,\n",
      "    \"LABEL_629\": 629,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_630\": 630,\n",
      "    \"LABEL_631\": 631,\n",
      "    \"LABEL_632\": 632,\n",
      "    \"LABEL_633\": 633,\n",
      "    \"LABEL_634\": 634,\n",
      "    \"LABEL_635\": 635,\n",
      "    \"LABEL_636\": 636,\n",
      "    \"LABEL_637\": 637,\n",
      "    \"LABEL_638\": 638,\n",
      "    \"LABEL_639\": 639,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_640\": 640,\n",
      "    \"LABEL_641\": 641,\n",
      "    \"LABEL_642\": 642,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /mount/studenten-temp1/users/knupleun/.cache/huggingface/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c11e1b37354cd4b49b951c57335a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6324373ff7e4805a78cd66e8206527f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c532658be2a34de1b8c45edbcc5a26e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 46120\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 5765\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 5765\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users1/knupleun/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 46120\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3575' max='14420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3575/14420 4:25:47 < 13:26:43, 0.22 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.468728</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.435289</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.389791</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.369172</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.367560</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.357754</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.340153</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.325827</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.002775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.324964</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.304521</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.287982</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.004683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.274808</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.275356</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.261368</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.005377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.250744</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.248973</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.243993</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.004510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.222735</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.006245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.199844</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>0.005724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.187763</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.005898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.206341</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>0.007112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.178153</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0.005551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.188886</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.170321</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.006938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.179530</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.007285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.127490</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.009193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.124690</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.014918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.109425</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.010061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.100806</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.009020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.095798</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.010581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.033072</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>0.014397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.025748</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.016690</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.013356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>6.043559</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.013010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>5.970411</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>0.014397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>5.953478</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.015611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>5.935704</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>5.925025</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>6.311300</td>\n",
       "      <td>5.938344</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.015091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.905841</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.014918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.892711</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.016652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.857199</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.020642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.862210</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>0.019254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.840380</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.018734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.862801</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.020295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.794948</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.023417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.788744</td>\n",
       "      <td>0.022550</td>\n",
       "      <td>0.022550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.834672</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.022897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.769187</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.024458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.756037</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.020295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.724216</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.021509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.705101</td>\n",
       "      <td>0.023244</td>\n",
       "      <td>0.023244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.712574</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.021336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.722012</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.024111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.673017</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>0.023070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.674376</td>\n",
       "      <td>0.023764</td>\n",
       "      <td>0.023764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.671167</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.022897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.640892</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>0.025672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>6.088900</td>\n",
       "      <td>5.628285</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.025846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.635130</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.024458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.635680</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>0.023070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.616972</td>\n",
       "      <td>0.026019</td>\n",
       "      <td>0.026019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.600449</td>\n",
       "      <td>0.026539</td>\n",
       "      <td>0.026539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.568074</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>0.028448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.567482</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.027233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.566845</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.025499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.555999</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.033825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.534594</td>\n",
       "      <td>0.032437</td>\n",
       "      <td>0.032437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.532015</td>\n",
       "      <td>0.035386</td>\n",
       "      <td>0.035386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.508922</td>\n",
       "      <td>0.032437</td>\n",
       "      <td>0.032437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.501942</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.033825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.513690</td>\n",
       "      <td>0.033304</td>\n",
       "      <td>0.033304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.517842</td>\n",
       "      <td>0.032264</td>\n",
       "      <td>0.032264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.483932</td>\n",
       "      <td>0.038508</td>\n",
       "      <td>0.038508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.450024</td>\n",
       "      <td>0.040069</td>\n",
       "      <td>0.040069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.460866</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.037988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.463657</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>0.040763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.429235</td>\n",
       "      <td>0.037294</td>\n",
       "      <td>0.037294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>5.768700</td>\n",
       "      <td>5.438203</td>\n",
       "      <td>0.040416</td>\n",
       "      <td>0.040416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.401056</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>0.040590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.407998</td>\n",
       "      <td>0.041110</td>\n",
       "      <td>0.041110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.403813</td>\n",
       "      <td>0.040937</td>\n",
       "      <td>0.040937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.385786</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.042498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.389383</td>\n",
       "      <td>0.039549</td>\n",
       "      <td>0.039549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.372369</td>\n",
       "      <td>0.043018</td>\n",
       "      <td>0.043018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.362439</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.044753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.372747</td>\n",
       "      <td>0.041284</td>\n",
       "      <td>0.041284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.382571</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.043712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.344370</td>\n",
       "      <td>0.048916</td>\n",
       "      <td>0.048916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.344628</td>\n",
       "      <td>0.048916</td>\n",
       "      <td>0.048916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.327636</td>\n",
       "      <td>0.051344</td>\n",
       "      <td>0.051344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.320620</td>\n",
       "      <td>0.052732</td>\n",
       "      <td>0.052732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.312412</td>\n",
       "      <td>0.052905</td>\n",
       "      <td>0.052905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.303361</td>\n",
       "      <td>0.050130</td>\n",
       "      <td>0.050130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.302871</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>0.053773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.284765</td>\n",
       "      <td>0.053252</td>\n",
       "      <td>0.053252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.271499</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.049783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.319378</td>\n",
       "      <td>0.047181</td>\n",
       "      <td>0.047181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>5.485400</td>\n",
       "      <td>5.267445</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.054814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.267450</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.049436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.246286</td>\n",
       "      <td>0.057242</td>\n",
       "      <td>0.057242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.240262</td>\n",
       "      <td>0.054467</td>\n",
       "      <td>0.054467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.252402</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>0.053773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.246439</td>\n",
       "      <td>0.054640</td>\n",
       "      <td>0.054640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.218272</td>\n",
       "      <td>0.056895</td>\n",
       "      <td>0.056895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.218587</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>0.057589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.232115</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>0.057415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.210532</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.060885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.259631</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0.060711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.217085</td>\n",
       "      <td>0.059150</td>\n",
       "      <td>0.059150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.203307</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>0.058630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.188491</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>0.055681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.185188</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>0.059497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.176166</td>\n",
       "      <td>0.063313</td>\n",
       "      <td>0.063313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.171845</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.057762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.164931</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.061232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.163714</td>\n",
       "      <td>0.058456</td>\n",
       "      <td>0.058456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.137918</td>\n",
       "      <td>0.061058</td>\n",
       "      <td>0.061058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>5.327600</td>\n",
       "      <td>5.160082</td>\n",
       "      <td>0.059670</td>\n",
       "      <td>0.059670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.171397</td>\n",
       "      <td>0.058283</td>\n",
       "      <td>0.058283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.132873</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0.060711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.132051</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>0.063140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.139847</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.061232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.120607</td>\n",
       "      <td>0.064354</td>\n",
       "      <td>0.064354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.112102</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.105316</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.116784</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.065915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.104373</td>\n",
       "      <td>0.066956</td>\n",
       "      <td>0.066956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.106760</td>\n",
       "      <td>0.064007</td>\n",
       "      <td>0.064007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.139882</td>\n",
       "      <td>0.064007</td>\n",
       "      <td>0.064007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.091451</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.067823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.097946</td>\n",
       "      <td>0.070598</td>\n",
       "      <td>0.070598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.079887</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.067823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.074790</td>\n",
       "      <td>0.064354</td>\n",
       "      <td>0.064354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.081571</td>\n",
       "      <td>0.072160</td>\n",
       "      <td>0.072160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.061145</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.070078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.059221</td>\n",
       "      <td>0.064007</td>\n",
       "      <td>0.064007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.050078</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.069731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>5.113100</td>\n",
       "      <td>5.047857</td>\n",
       "      <td>0.070945</td>\n",
       "      <td>0.070945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.846800</td>\n",
       "      <td>5.036772</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.077363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>4.846800</td>\n",
       "      <td>5.062920</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.072507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>4.846800</td>\n",
       "      <td>5.053633</td>\n",
       "      <td>0.068170</td>\n",
       "      <td>0.068170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>4.846800</td>\n",
       "      <td>5.039273</td>\n",
       "      <td>0.073374</td>\n",
       "      <td>0.073374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3000\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3000/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3500\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3500/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [/mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/checkpoint-3500 (score: 0.07736339982653946).\n",
      "Saving model checkpoint to /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643\n",
      "Configuration saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/config.json\n",
      "Model weights saved in /mount/studenten-temp1/users/knupleun/artist-classification/models/bert-643/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5765\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='361' max='361' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [361/361 01:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_folder = '../data/'\n",
    "class_subsets = [10, 20, 50, 100, 200, 400, 642]\n",
    "\n",
    "results_file = '../results.csv'\n",
    "for subset in class_subsets:\n",
    "    dataset, artists = get_dataset(dataset_folder, subset)\n",
    "\n",
    "    results = run_bert_experiment(artists, dataset)\n",
    "\n",
    "    write_bert_results(results_file, results, dataset, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# ==== kNN ====\n",
    "#################\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "def transform(example):\n",
    "    example['lyrics'] = example['lyrics'].replace(' NEWLINE ', ' [SEP] ')\n",
    "\n",
    "    return example\n",
    "\n",
    "def get_embeddings(model_path, artists, dataset):\n",
    "    model = AutoModel.from_pretrained(model_path, output_hidden_states=True).to('cuda')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    tokenized_dataset = dataset.map(transform, load_from_cache_file=False)\n",
    "\n",
    "    batch_size = 64\n",
    "    num_shards = len(tokenized_dataset) // batch_size \n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for i in tqdm(range(num_shards)):\n",
    "        shard = tokenized_dataset.shard(num_shards=num_shards, index=i)\n",
    "        model_inputs = tokenizer(shard['lyrics'], padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "        labels.extend(artists.str2int(shard['artist']))\n",
    "\n",
    "        # Info on getting hidden state embeddings\n",
    "        # https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#32-understanding-the-output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**model_inputs)\n",
    "\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "            # Getting single vector representations by averaging the second to last hiden layer of each token producing a single 768 length vector.\n",
    "            token_vecs = hidden_states[-2]\n",
    "\n",
    "\n",
    "            # Calculate the average of all 512 token vectors (that's the size of the input)\n",
    "            # Using the second dimension, because the first representes each lyric\n",
    "            sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "            sentence_embedding = sentence_embedding.cpu().detach().numpy()\n",
    "\n",
    "            embeddings.extend(sentence_embedding)\n",
    "\n",
    "\n",
    "    del model\n",
    "    del tokenizer \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return embeddings, labels\n",
    "\n",
    "def run_knn_experiment(model_path, artists, dataset):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    train_embeddings, train_labels = get_embeddings(model_path, artists, dataset['train'])\n",
    "    test_embeddings, test_labels = get_embeddings(model_path, artists, dataset['test'])\n",
    "\n",
    "    neigh = KNeighborsClassifier(weights=\"distance\")\n",
    "    neigh.fit(train_embeddings, train_labels)\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import evaluate\n",
    "\n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def evalute_knn(embeddings, references):\n",
    "        diff_setups = []\n",
    "        for n in range(1,26):\n",
    "            neigh.set_params(n_neighbors=n)\n",
    "            predictions = neigh.predict(embeddings)\n",
    "\n",
    "            diff_setups.append({'n': n, 'predictions': predictions})\n",
    "\n",
    "        scores = []\n",
    "        n_neighbours = []\n",
    "        for i, setup in enumerate(diff_setups):\n",
    "            metric = acc_metric.compute(predictions=setup['predictions'], references=references)\n",
    "\n",
    "            score = metric['accuracy']\n",
    "            scores.append(score)\n",
    "            n_neighbours.append(i + 1)\n",
    "\n",
    "        return n_neighbours, scores\n",
    "\n",
    "\n",
    "    n_neighbours, scores = evalute_knn(test_embeddings, test_labels)\n",
    "\n",
    "    plt.plot(n_neighbours, scores)\n",
    "\n",
    "    print()\n",
    "    print('Training examples:', len(train_embeddings))\n",
    "    print('Test examples:', len(test_embeddings))\n",
    "    plt.show()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return n_neighbours, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2928ec9aac5245af8b84356bc68e1aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fe1d92e42689c93a.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f4be0b13fbefb833.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-51c951e8f43d925d.arrow\n",
      "Some weights of the model checkpoint at ../models/bert-10/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e390e1847af04a24b021a9a350491f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/657 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d4f14593b847d490d2a0ffd9149956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-10/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b299c05f0084631a13bcca37c4d6c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8596c7566d614e66a4100bebbcea6205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 657\n",
      "Test examples: 83\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622786afe81c454881a1878641a57e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c94e11b00638522b.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-8854d2a8022a2511.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fbd266e8e1244cbb.arrow\n",
      "Some weights of the model checkpoint at ../models/bert-20/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07006d68fab34feaa13bd24a3b98f3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1298 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bec36492e734df18f50c325a1351063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-20/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89f7db3b7e344b98c2e1e8dedcd3e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1588eee4994b1c8512ed64b8d20d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 1298\n",
      "Test examples: 168\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592b954dc35747d39ce4a0fd49021d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3711c0cb0ca17cc5.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e2098fad4ac2fb9f.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6fbc8ecd1cb6cb08.arrow\n",
      "Some weights of the model checkpoint at ../models/bert-50/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be11617af743443a9a90a4619ae804d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3751 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e842992dcbd48798cd0720ee6f10228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-50/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeffab3b3cc344f4a952a90ac8dbdfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9febc6d8a0ee42c8b4ec2991383bf084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 3751\n",
      "Test examples: 440\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5414cfe0b2465baf325c7c131f93df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-7a80d14753f271d7.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b6d88e22e3be6349.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f87ff85dd9ca033a.arrow\n",
      "Some weights of the model checkpoint at ../models/bert-100/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c8aa44ff94e65a0ea204930cffec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7236 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2836c649ff4838baada615fa31b45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-100/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34ae9b737164aec8a3ee8c860b4a820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/863 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b76797b65a149af91456efa32a60570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 7236\n",
      "Test examples: 863\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb66a3e2cd84642a853163857015033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-84058cc242281cf8.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-36326db3c5245f26.arrow\n",
      "Loading cached processed dataset at /mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-551d687df36bcaf1.arrow\n",
      "Some weights of the model checkpoint at ../models/bert-200/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee7dfdf847c47389ff6742ddc943cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14635 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb11cb657f74477b3bfe63004cde51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-200/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1537199013ec4cd299013e5d853ca4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1819 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7926efc5d93841da9e28f9d532716df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 14635\n",
      "Test examples: 1819\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58707ebf42e41c2af33dab9c35db77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed41f1b5866425297598a62ab3eab3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623446092add4c99abdb1bb4d19a1c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb66b7b0c5b4511a8941651434c0850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-400/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19162180a7404f12aff6844e8d2d2739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29188 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ce180485ac4704bf2c6be1509a2a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-400/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dfa732cd9b41c4b52c599d5957c094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3586 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18ca8244e58472b87808c88f040c517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 29188\n",
      "Test examples: 3586\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74da23bab6946fca93657236507f926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like ../models/bert-642/ is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    602\u001b[0m         config_file,\n\u001b[1;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    604\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    605\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    606\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    607\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    608\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    285\u001b[0m         url_or_filename,\n\u001b[1;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:554\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m                 )\n\u001b[1;32m    559\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000021vscode-remote?line=5'>6</a>\u001b[0m dataset, artists \u001b[39m=\u001b[39m get_dataset(dataset_folder, subset)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000021vscode-remote?line=7'>8</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../models/bert-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(subset) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000021vscode-remote?line=8'>9</a>\u001b[0m n, results \u001b[39m=\u001b[39m run_knn_experiment(model_path, artists, dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000021vscode-remote?line=10'>11</a>\u001b[0m write_knn_results(results_file, results, dataset, artists)\n",
      "\u001b[1;32m/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb Cell 9'\u001b[0m in \u001b[0;36mrun_knn_experiment\u001b[0;34m(model_path, artists, dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_knn_experiment\u001b[39m(model_path, artists, dataset):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=55'>56</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=57'>58</a>\u001b[0m     train_embeddings, train_labels \u001b[39m=\u001b[39m get_embeddings(model_path, artists, dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=58'>59</a>\u001b[0m     test_embeddings, test_labels \u001b[39m=\u001b[39m get_embeddings(model_path, artists, dataset[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=60'>61</a>\u001b[0m     neigh \u001b[39m=\u001b[39m KNeighborsClassifier(weights\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb Cell 9'\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(model_path, artists, dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embeddings\u001b[39m(model_path, artists, dataset):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=14'>15</a>\u001b[0m     model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_path, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=15'>16</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstrauss.ims/mount/studenten-temp1/users/knupleun/artist-classification/notebooks/bert-diff-classes.ipynb#ch0000013vscode-remote?line=17'>18</a>\u001b[0m     tokenized_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(transform, load_from_cache_file\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:423\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_auto\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 423\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    424\u001b[0m         pretrained_model_name_or_path, return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[1;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:705\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    704\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 705\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    552\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    555\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    635\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    638\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m library in offline mode at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m     )\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like ../models/bert-642/ is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "dataset_folder = '../data/'\n",
    "class_subsets = [10, 20, 50, 100, 200, 400, 642]\n",
    "\n",
    "results_file = '../results.csv'\n",
    "for subset in class_subsets:\n",
    "    dataset, artists = get_dataset(dataset_folder, subset)\n",
    "\n",
    "    model_path = '../models/bert-' + str(subset) + '/'\n",
    "    n, results = run_knn_experiment(model_path, artists, dataset)\n",
    "\n",
    "    write_knn_results(results_file, results, dataset, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-326223662ac9146d\n",
      "Reusing dataset csv (/mount/studenten-temp1/users/knupi/.cache/huggingface/csv/default-326223662ac9146d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0815657885b4fda89de8fd8a509685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-643/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004e3b981e254217bdcfa6bacf842460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46120 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b28d35348046808771f236a8e56398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/bert-643/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027c5cc227c4aa5bc48d8572c692e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5765 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a668861d13647199ab9185965b7419e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 46120\n",
      "Test examples: 5765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_folder = '../data/'\n",
    "class_subsets = [643]\n",
    "\n",
    "results_file = '../results.csv'\n",
    "for subset in class_subsets:\n",
    "    dataset, artists = get_dataset(dataset_folder, subset)\n",
    "\n",
    "    model_path = '../models/bert-' + str(subset) + '/'\n",
    "    n, results = run_knn_experiment(model_path, artists, dataset)\n",
    "\n",
    "    write_knn_results(results_file, results, dataset, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teamlabs",
   "language": "python",
   "name": "teamlabs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "29fa6e2f6b483c73741f762295f0b20abd4d37c3114673c02b7680f42a83ec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
